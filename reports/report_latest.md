## 2024-07-19

## Generative AI applied to supporting software developers
### Case2Code: Learning Inductive Reasoning with Synthetic Data
ðŸ’¡ *Why it's relevant*: This paper focuses on teaching LLMs to conduct inductive reasoning, a skill crucial for software development tasks like code completion and bug fixing. It proposes a novel task called Case2Code, where LLMs are trained to infer underlying code implementations from synthetic input-output examples. This approach could lead to the development of AI tools that can better understand and generate code based on user input and existing code examples.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2407.12504)

## Prompt engineering techniques that improve AI system performance
### The Art of Saying No: Contextual Noncompliance in Language Models
ðŸ’¡ *Why it's relevant*:  This paper tackles the issue of making AI systems more responsible and less likely to generate harmful or inappropriate outputs.  It proposes a taxonomy of contextual noncompliance, highlighting situations where AI models should "say no" to user requests, beyond just unsafe ones. The paper explores techniques to improve models' noncompliance capabilities, which has direct implications for ethical and safe development of AI systems for HCI applications.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2407.12043)

## Human-in-the-loop machine learning for improved training or evaluation
### FIRE: A Dataset for Feedback Integration and Refinement Evaluation of Multimodal Models
ðŸ’¡ *Why it's relevant*: This paper introduces FIRE, a feedback-refinement dataset, that allows researchers to evaluate how VLMs can adapt their responses based on user feedback. This dataset can be used to develop and assess human-in-the-loop approaches for improving the training and evaluation of VLMs, particularly in applications where user feedback is crucial.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2407.11522)

## Applications of Generative AI in user interface design and engineering
### IMAGDressing-v1: Customizable Virtual Dressing
ðŸ’¡ *Why it's relevant*: This paper proposes IMAGDressing-v1, a virtual dressing system that allows users to control various aspects of generated images, including clothing, faces, poses, and scenes. This technology could revolutionize user interface design by enabling designers to quickly create and iterate on various UI concepts using text prompts and AI-generated visuals.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2407.12705)

## Techniques to explain AI systems behavior to users
### Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models
ðŸ’¡ *Why it's relevant*: This paper investigates the fragility of uncertainty estimation in LLMs, showcasing how attackers can manipulate the model's confidence without altering its output. This research sheds light on the challenges associated with explainable AI and emphasizes the need for robust techniques to ensure that users can trust and understand the reasoning behind AI system decisions.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2407.11282)
