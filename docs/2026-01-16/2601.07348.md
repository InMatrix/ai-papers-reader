---
layout: paper
pdf_url: https://arxiv.org/pdf/2601.07348
permalink: 2026-01-16/2601.07348/
title: New Framework Teaches AI to Write Code That is Fast, Not Just Correct
---



Large Language Models (LLMs) have become proficient at generating functional code, but a persistent flaw plagues their output: inefficiency. While an LLM might quickly solve a complex coding challenge, its solution often exhibits poor algorithmic complexity, demanding excessive time and memory compared to human expert code.

Researchers have introduced a novel framework called Controlled Self-Evolution (CSE) that addresses this critical gap, allowing LLMs to iteratively refine and optimize code with significantly higher efficiency. Tested on the comprehensive algorithmic benchmark EffiBench-X, CSE consistently outperformed existing state-of-the-art self-evolution methods across diverse LLM backbones, including DeepSeek and GPT-5, achieving marked improvements in Execution Time (ET), Memory Peak (MP), and Memory Integral (MI) ratios relative to human performance.

Existing self-evolution methods suffer from low exploration efficiency, characterized by random, unguided changes and a tendency to get stuck in poor initial solutions. The CSE framework overcomes these limitations through three core innovations designed to impose structure and guidance on the search process.

### Guided Exploration, Not Random Walk

The first component is **Diversified Planning Initialization**. Instead of starting the evolutionary process from one or two code snippets, which often results in "initialization bias," CSE prompts the LLM to generate multiple, structurally distinct algorithmic sketches.

For example, when solving a complex problem like finding optimal paths, an existing method might only generate superficial variations of a single approach (e.g., one type of greedy algorithm). CSE forces the generation of fundamentally different strategies—such as a dynamic programming solution, a graph-based search, and a bit manipulation optimization—ensuring the evolutionary loop explores multiple high-potential regions of the solution space from the outset.

The second innovation, **Genetic Evolution**, replaces blind trial-and-error with surgically precise code modifications. This involves two key mechanisms:

1.  **Controlled Mutation:** The agent first decomposes the code into functional components (like input/output handling, core logic, and boundary cases). If the performance feedback reveals the core logic is the bottleneck, the LLM performs targeted regeneration *only* on that faulty module, leaving the remaining, well-performing components frozen and intact.
2.  **Compositional Crossover:** This operator allows the system to breed new, superior solutions by merging complementary strengths from two parent candidates. If Parent A has an excellent time-efficient algorithm but slow input parsing, and Parent B has robust, fast I/O but a slightly worse core algorithm, the crossover structurally integrates Parent A's core with Parent B's I/O module.

### Learning from Success and Failure

The third and most crucial component is the **Hierarchical Evolution Memory**, which captures and reuses experiences at both local (intra-task) and global (inter-task) levels.

**Local Memory** acts like a detailed logbook for the current problem, recording both successful optimization patterns and, critically, failure lessons. If a specific data structure choice led to an immediate crash (memory failure), the local memory ensures the agent avoids that choice in subsequent generations, preventing redundant exploration.

The **Global Memory** distills generalizable optimization heuristics across different tasks, functioning as a reusable knowledge base. When tackling a new problem, the system can query this memory for relevant optimization strategies—for instance, retrieving lessons on how to reduce memory consumption in dynamic programming across a large dataset.

The research demonstrates that this combined approach allows CSE to achieve superior performance faster in early iterations and maintain continuous improvements throughout the limited optimization budget. The ability to learn from past failures and guide the search using structural, rather than stochastic, means CSE is capable of achieving high code quality where prior self-evolution models quickly hit a ceiling.