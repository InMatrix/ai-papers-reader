---
layout: paper
pdf_url: https://arxiv.org/pdf/2601.08079
permalink: 2026-01-16/2601.08079/
title: '"MemoBrain" Gives AI Agents an Executive Function to Master Complex, Long-Horizon
  Tasks'
---



Artificial intelligence agents equipped with external tools like web search or code execution have proven highly capable, but their competence often collapses when faced with complex, long-horizon tasks. An excessive build-up of temporary tool outputs and failed reasoning steps quickly overwhelms the limited working context of large language models (LLMs), leading to cognitive overload and logical incoherence.

To solve this critical bottleneck, researchers have introduced **MemoBrain**, an "executive memory" system designed to function as a cognitive co-pilot alongside the reasoning agent. MemoBrain reconceptualizes memory not as passive storage, but as an active, dependency-aware control mechanism that manages information flow to sustain task coherence under a bounded context budget.

MemoBrain’s core innovation is its ability to extract a high-salience reasoning backbone from noisy execution traces. It achieves this through two complementary processes: memory construction and active memory management.

During **memory construction**, the system asynchronously abstracts detailed, transient execution sessions—such as raw search results, unsuccessful query attempts, or internal deliberations—into compact, structured memory units called "thoughts." These thoughts capture only the decisive semantic outcome of an episode (e.g., "Subtask A resolved, relevant evidence found") and establish explicit dependency links to prior conclusions.

For example, imagine an agent performing a complex research query. Instead of flooding the context window with the verbose record of "I tried search query 1, found irrelevant results; I refined to search query 2, received 10 pages of mixed relevance; I refined again to query 3, found the target evidence," MemoBrain abstracts this entire messy sequence into a single, compact "thought" preserving only the final, useful conclusion and its relation to the overall task.

When the agent's context window approaches its budget limit, MemoBrain actively regulates the accumulated trajectory using executive operations:

1. **Sequential Trajectory Folding:** This operation collapses sequences of related thoughts that have reached a conclusive resolution (a completed sub-trajectory) into a single, comprehensive summary thought. If an agent spent 15 steps validating a single fact, those 15 steps are folded into one summary, freeing up significant context space while retaining the verified conclusion.
2. **Selective Memory Flush:** This identifies and removes low-utility or superseded information, such as exploratory attempts that failed to yield meaningful feedback. This ensures the working context remains focused on the active reasoning path.

Evaluated across challenging benchmarks, including GAIA and WebWalker, MemoBrain consistently delivered substantial performance improvements, especially on the hardest reasoning splits where long-horizon interaction strains conventional LLM agents.

Furthermore, efficiency studies confirmed that MemoBrain, operating in its asynchronous, co-pilot role, adds negligible latency. By delivering compact, just-in-time contextual support, MemoBrain enables agents to effectively reason over trajectories spanning hundreds of thousands of tokens while strictly adhering to a small fixed context budget (e.g., 32K tokens). This design successfully extends the practical reasoning horizon of tool-augmented AI systems without requiring massive model context expansion.