## 2024-06-21

## Generative AI applied to supporting software developers
### AgileCoder: Dynamic Collaborative Agents for Software Development based on Agile Methodology
ðŸ’¡ *Why it's relevant*: This paper proposes a multi-agent system that integrates Agile Methodology (AM) into software development, enhancing efficiency by organizing work into sprints and dynamically generating a code dependency graph. This approach offers a compelling way to leverage generative AI for collaborative development workflows, providing insights for human-computer interaction in software engineering.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.11912)

### REPOEXEC: Evaluate Code Generation with a Repository-Level Executable Benchmark
ðŸ’¡ *Why it's relevant*: This paper introduces a benchmark for evaluating code generation at the repository-level scale, focusing on executability, functional correctness, and cross-file contexts. By analyzing the performance of different models in this setting, researchers can better understand the limitations and opportunities for generative AI in supporting real-world software development.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.11927)

## Prompt engineering techniques that improve AI system performance
### Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities
ðŸ’¡ *Why it's relevant*:  This paper introduces a simple yet effective method, whiteboard-of-thought prompting, to unlock the visual reasoning capabilities of multimodal large language models. By prompting models to draw out reasoning steps as images, this technique helps bridge the gap between text-based reasoning and visual understanding, presenting a new approach to prompt engineering for complex tasks.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.14562)

### Instruction Pre-Training: Language Models are Supervised Multitask Learners
ðŸ’¡ *Why it's relevant*: This paper proposes a framework for supervised multitask pre-training called Instruction Pre-Training, which enhances pre-trained language models by augmenting raw corpora with instruction-response pairs. This approach demonstrates the potential for large-scale supervised learning to improve model performance and adaptability across various tasks, offering a new direction for prompt engineering in multitask settings.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.14491)

## Human-in-the-loop machine learning for improved training or evaluation
### Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces
ðŸ’¡ *Why it's relevant*: This paper proposes a new methodology for evaluating unlearning methods in large language models by considering changes in the parametric knowledge traces of unlearned concepts. It addresses a critical aspect of human-in-the-loop learning by highlighting the importance of internal evaluation for ensuring that unwanted knowledge is effectively removed from models.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.11614)

### Measuring memorization in RLHF for code completion
ðŸ’¡ *Why it's relevant*: This paper analyzes how training data memorization can surface and propagate through different stages of reinforcement learning with human feedback (RLHF). By investigating the relationship between memorization and RLHF, this paper provides valuable insights for understanding and mitigating potential privacy concerns in human-in-the-loop model training.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.11715)

## Applications of Generative AI in user interface design and engineering
### HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors
ðŸ’¡ *Why it's relevant*: This paper presents a new method, HumanSplat, for predicting the 3D Gaussian Splatting properties of any human from a single input image, enabling photorealistic novel-view synthesis. This has implications for user interface design by allowing for more realistic and interactive 3D representations of humans in virtual environments, fostering more immersive and engaging user experiences.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.12459)

### ExVideo: Extending Video Diffusion Models via Parameter-Efficient Post-Tuning
ðŸ’¡ *Why it's relevant*:  This paper introduces a novel post-tuning methodology for video synthesis models called ExVideo, allowing them to generate longer videos with reduced training costs. This development has the potential to revolutionize user interface design by enabling more dynamic and engaging video experiences, such as personalized content creation and interactive storytelling.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.14130)

## Techniques to explain AI systems behavior to users
### Probabilistic Conceptual Explainers: Trustworthy Conceptual Explanations for Vision Foundation Models
ðŸ’¡ *Why it's relevant*: This paper proposes a variational Bayesian explanation framework, dubbed ProbAbilistic Concept Explainers (PACE), for providing trustworthy post-hoc conceptual explanations for vision transformer models. By offering multi-level explanations and addressing key desiderata for explainability, PACE lays a foundation for more transparent and user-friendly AI systems in visual domains.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.12649)

### Estimating Knowledge in Large Language Models Without Generating a Single Token
ðŸ’¡ *Why it's relevant*: This paper introduces KEEN, a simple probe that can estimate the knowledge of a language model about a certain entity without requiring the model to generate any text. This has implications for explainable AI by enabling more efficient and transparent methods for identifying knowledge gaps and understanding the reasoning behind model outputs.

ðŸ‘‰ [ Read full paper](https://arxiv.org/pdf/2406.12673) 
