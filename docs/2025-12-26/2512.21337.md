---
layout: paper
pdf_url: https://arxiv.org/pdf/2512.21337
permalink: 2025-12-26/2512.21337/
title: Study Finds AI Models Are Architectural Tourists, Memorizing Landmarks Over
  True Understanding
---



A new open benchmark reveals a significant popularity bias in state-of-the-art Vision-Language Models (VLMs), suggesting these advanced AI systems excel at memorizing famous landmarks but struggle to identify the construction year of ordinary buildings.

According to a paper published by researchers at National Yang Ming Chiao Tung University, VLMs show up to 34% higher accuracy when predicting the age of well-known, highly-viewed structures compared to less popular ones. This pattern exposes a critical reliance on rote memorization gleaned from massive training datasets, rather than genuine architectural reasoning capabilities.

To systematically investigate this "memorization bias," the researchers introduced **YearGuessr**, the largest open benchmark for building-age estimation. The dataset comprises 55,546 building facade images sourced globally from Wikipedia across 157 countries, spanning a massive 1,000-year history from 1001 to 2024 CE. Crucially, the dataset includes multi-modal metadata, including GPS coordinates, textual descriptions, and Wikipedia page-view counts, which serve as a proxy for building popularity.

The ability to accurately predict a building’s construction year is vital for applications ranging from sustainable urban retrofitting and fine-grained historical queries to heritage preservation. However, the study found that current commercial models, especially closed-source VLMs, are unreliable on unrenowned subjects.

In testing against more than 30 models, including CNNs, Transformers, and major commercial VLMs like Gemini and Grok, the popularity bias was starkly evident. For instance, the Gemini2.0-Flash model achieved a remarkable **+34.18%** gain in prediction accuracy on buildings with very high popularity (over 100,000 annual page views) compared to low-popularity structures (under 100 views). This suggests the model is simply recalling data associated with well-documented sites rather than analyzing the architectural style.

To address this gap, the researchers proposed their own baseline model, **YearCLIP**, which frames the age prediction task as ordinal regression—treating age as a ranked, continuous sequence rather than simple classification. YearCLIP integrates image data, GPS coordinates, and specialized architectural "reasoning prompts."

These reasoning prompts allow YearCLIP to provide a human-verifiable rationale for its prediction. For example, when estimating a built year of 1687 for a church, the model might specify the decision was based on identifying "Baroque style," noting architectural cues such as a "domed roof," masonry construction, and "arched windows." This transparent approach helps confirm that the model is performing genuine visual-linguistic reasoning grounded in architectural features.

Beyond popularity, the benchmark also exposed other pervasive biases. Most models performed significantly better when dating modern, post-1800 buildings compared to ancient, pre-1600 structures, and showed geographic disparities, achieving the lowest average error in the Americas and Australia, reflecting skewed pre-training data.

The YearGuessr benchmark is intended to serve as a critical tool for the research community, providing public metrics to quantify and ultimately mitigate these memorization flaws, pushing models toward generalizable architectural understanding crucial for reliably assessing the world’s vast inventory of unknown buildings.