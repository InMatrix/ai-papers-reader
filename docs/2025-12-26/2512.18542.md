---
layout: paper
pdf_url: https://arxiv.org/pdf/2512.18542
permalink: 2025-12-26/2512.18542/
title: New Production-Grade Dataset SecureCode v2.0 Aims to Fix AI Coding Assistants’
  Security Crisis
---



A new dataset, SecureCode v2.0, has been released to tackle the rising security crisis caused by Artificial Intelligence (AI) coding assistants, which are reported to introduce vulnerabilities in nearly half of the code they generate in security-relevant contexts.

Developed by Scott Thornton and colleagues, the dataset provides 1,215 meticulously validated, real-world examples specifically designed to train large language models (LLMs) to prioritize security, operational hardening, and incident response, moving beyond simple code fixes.

Recent reports highlight the urgency of this challenge: studies show that AI copilots introduce significantly more privilege escalation paths and architectural design flaws than manually written code, actively degrading enterprise security posture. Existing security datasets, such as the widely used Juliet Test Suite, fail to address this because they rely on synthetic, hypothetical examples lacking connections to real-world breaches or production contexts.

### Grounding Security in Real Incidents

SecureCode v2.0 differentiates itself by achieving 100% “incident grounding.” Every example in the dataset is tied directly to documented security incidents, complete with CVE references (Common Vulnerabilities and Exposures), or real-world breach reports.

For instance, rather than demonstrating a generic injection flaw, the dataset might model a vulnerability pattern drawn from the 2017 Equifax breach (CVE-2017-5638), which stemmed from an Apache Struts 2 remote code execution vulnerability. By anchoring training data in such documented failures, LLMs learn exploit patterns that actually lead to business impact.

The dataset is comprehensive, covering 11 vulnerability categories—including the complete OWASP Top 10:2025 and emerging AI/ML security threats—across 11 programming languages, including Python, JavaScript, Java, Go, and YAML for infrastructure-as-code.

### Training Models on Realistic Workflows

Crucially, SecureCode v2.0 introduces a novel 4-turn conversational structure that mirrors how developers actually interact with AI assistants in production environments.

Most previous datasets only offer code-snippet pairs (vulnerable versus secure). SecureCode v2.0 structures its examples as an iterative security workflow:

1.  **Turn 1 (User Request):** The developer asks for basic functionality, such as "build user authentication with JWT tokens," without explicitly mentioning security.
2.  **Turn 2 (AI Response):** The AI assistant provides both the vulnerable implementation (a common, realistic mistake) and the secure implementation, alongside a concrete attack demonstration to show how the flaw works.
3.  **Turn 3 (User Pressure Test):** The developer escalates the request, asking about scaling or edge cases, such as "how does this scale to 10,000 concurrent users?"
4.  **Turn 4 (AI Operational Guidance):** The assistant delivers comprehensive "defense-in-depth" advice, including logging and monitoring strategies, SIEM (Security Information and Event Management) integration recommendations, and infrastructure hardening tips (e.g., Docker configurations or WAF rules).

This format ensures that models are trained to maintain security context even as development concerns shift to performance and scaling, teaching operational completeness rather than just code-level fixes.

The entire dataset, along with its automated validation framework used to ensure 100% quality compliance, has been released open-source, providing a critical resource for researchers and enterprises seeking to fine-tune AI copilots for secure development.