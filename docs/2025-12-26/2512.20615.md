---
layout: paper
pdf_url: https://arxiv.org/pdf/2512.20615
permalink: 2025-12-26/2512.20615/
title: AI Avatars Gain Genuine Agency Through Closed-Loop World Modeling
---



A new framework called ORCA (Online Reasoning and Cognitive Architecture) is enabling video avatars to transition from passive, script-following animations into actively intelligent agents capable of pursuing long-term goals in complex virtual environments.

Developed by researchers from The Hong Kong University of Science and Technology and Meituan, ORCA addresses the fundamental limitation of current generative avatars: their lack of "genuine agency." Existing systems can align motion to speech or pre-defined poses, but they cannot adaptively plan multiple steps or correct errors when interacting with a dynamic scene.

To foster this shift, the team introduced the L-IVA (Long-horizon Interactive Visual Avatar) task, a new benchmark that evaluates goal-directed planning. Crucially, L-IVA models the generative environment as a Partially Observable Markov Decision Process (POMDP). This accounts for the inherent unpredictability—or *stochasticity*—of the underlying Image-to-Video (I2V) models, where the same action command can yield inconsistent visual outcomes.

### The Self-Correcting Architecture

ORCA imbues avatars with an Internal World Model (IWM) that continuously tracks the state of the world, a necessity for robust, long-horizon planning. This is achieved through two major innovations.

First, ORCA operates on a closed-loop **Observe-Think-Act-Reflect (OTAR) cycle**.

In conventional open-loop planning, an agent plans a sequence of actions upfront and executes them blindly. In L-IVA, if the I2V model fails to accurately render a sub-goal—for instance, if an avatar intends to "scoop tea leaves" (Act), but the generative model visually misses the target object—the agent's internal belief about the scene becomes instantly corrupted.

The Reflect step in ORCA actively prevents this "belief corruption." The agent continuously verifies the predicted outcome (Think) against the actual generated video clip (Observe). If there is a mismatch, the agent rejects the result and triggers an error correction or replanning phase.

### Dual Systems for Coherence and Precision

Second, ORCA uses a **Hierarchical Dual-System Architecture**, separating strategic reasoning (System 2) from precise execution grounding (System 1).

*   **System 2 (Strategic Planner):** Functions during the Think and Reflect stages. It uses high-level reasoning to decompose the main intention (e.g., "Make Tea") into subgoals ("Open canister," "Scoop tea leaves"). System 2 maintains the long-term strategic coherence.
*   **System 1 (Action Grounder):** Operates during the Act stage. It translates the abstract subgoals from System 2 into detailed, model-specific action captions necessary for the I2V generator to execute precisely (e.g., "The man uses the hand on the left side of the image to pick up the red cup..."). This ensures execution fidelity, especially for fine-grained manipulations.

In complex scenarios like the "Transfer Plant" task, where an avatar must coordinate four sequential subgoals while maintaining object consistency, ORCA significantly outperformed baselines. Non-reflective agents repeatedly failed because early execution errors went undetected, leading to physically implausible, repetitive behaviors (like continuously adding soil when the pot was already full).

By continuously verifying its actions against its internal world model, ORCA delivered the highest task success rate and behavioral coherence, marking a significant step toward creating virtual humans with genuine, active intelligence. The researchers suggest that as the underlying large language and video models improve, ORCA's performance will scale without needing fundamental architectural changes.