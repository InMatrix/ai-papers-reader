---
layout: paper
pdf_url: https://arxiv.org/pdf/2512.18746
permalink: 2025-12-26/2512.18746/
title: LLM Agents Evolve How They Learn&#58; New Framework Builds Adaptive Memory
  Architectures
---



As large language model (LLM) agents take on increasingly complex, real-world tasks—from scientific discovery to web research—their ability to learn and improve is paramount. While current agents excel at accumulating knowledge (experiential evolution), this capacity is fundamentally constrained by their static memory architecture. These systems, whether they rely on vector databases or knowledge graphs, use fixed structures for storing and retrieving information, regardless of the task domain.

Researchers from the OPPO AI Agent Team and LV-NUS lab have introduced **MemEvolve**, a meta-evolutionary framework designed to solve this architectural rigidity. MemEvolve enables the dual evolution of both an agent’s experiential knowledge *and* the underlying memory architecture itself, allowing agents to progressively refine *how* they learn from experience.

The core analogy, according to the researchers, is the transition from a "skillful learner" (who has a fixed learning strategy) to an "adaptive learner" (who dynamically adjusts strategies based on the subject). A skillful learner might always use rote memorization, while an adaptive learner prioritizes abstracting reusable templates for mathematics and memorization for literary analysis.

### The Dual-Evolution Engine

MemEvolve achieves this adaptation through a bilevel optimization process involving two nested loops:

1.  **The Inner Loop (Experience Evolution):** The agent interacts with the environment, guided by its current memory architecture, accumulating trajectories and knowledge.
2.  **The Outer Loop (Architectural Evolution):** Based on empirical feedback from the inner loop—including task success, API cost, and execution delay—the memory architecture is updated. This crucial meta-learning phase uses a "Diagnose-and-Design" step to identify bottlenecks and generate new memory variants.

To make this evolution tractable, the team created **EvolveLab**, a unified codebase that modularizes any memory system into four distinct components: **Encode** (transforming raw experience into structured insights), **Store** (committing the information), **Retrieve** (context-aware recall), and **Manage** (consolidation or forgetting). By operating on these modular components, MemEvolve can swap out entire strategies. For example, it might evolve an **Encode** module from simply compressing raw traces to extracting nine specific skill granularities.

### Intuition Through Adaptation

The benefit of this dynamic design is evident in how evolved memory guides agents through tasks. On challenging benchmarks like xBench-DeepSearch, an agent using an evolved memory system doesn’t just retrieve past relevant documents; it receives context-sensitive guidance. During the initial planning phase, the memory might provide high-level task decomposition strategies. Later, during execution, it dynamically switches to offering fine-grained **Tool-use Suggestions** tailored to the specific step, or even providing predictive hints, anticipating information that might be found in image captions on travel websites.

This adaptive strategy leads to substantial performance improvements. Evaluations across four challenging agentic benchmarks, including GAIA and WebWalkerQA, show that MemEvolve delivers consistent and robust gains. The framework boosted the performance of leading systems like Flash-Searcher and SmolAgent by up to 17.06%.

Furthermore, memory architectures evolved on one task domain, **TaskCraft** (a synthetic task generation benchmark), showed strong **cross-generalization**, transferring effectively to entirely unseen benchmarks like WebWalkerQA and xBench-DS. These transferable architectures yielded performance gains even when the underlying LLM backbone was switched from GPT-5-MINI to models like Kimi K2 or DeepSeek V3.2, demonstrating that MemEvolve is discovering fundamental, framework-agnostic principles of smart memory design for continually improving AI agents.