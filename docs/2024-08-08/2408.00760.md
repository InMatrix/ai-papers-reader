---
layout: paper
pdf_url: https://arxiv.org/pdf/2408.00760
permalink: 2024-08-08/2408.00760/
title: New AI Guidance Method Smooths Diffusion Model 'Energy Landscape' for Sharper,
  Unconditional Image Generation
---



A new technique called Smoothed Energy Guidance (SEG) is offering diffusion models like Stable Diffusion XL a powerful, training-free way to enhance image quality, particularly when generating content without explicit text prompts. Developed by researchers at the University of Washington, SEG leverages an energy-based view of the self-attention mechanism to mitigate the common flaws associated with traditional guidance methods.

The success of modern generative models hinges largely on Classifier-Free Guidance (CFG), which sharpens the output distribution to produce high-fidelity images, but critically requires a conditional input (like a text prompt) and often introduces unwanted side effects—such as color saturation or structural distortion—when guidance is pushed too high.

SEG overcomes these limitations by approaching the self-attention process—the mechanism that determines relevance between different parts of the image—from the perspective of an energy function. The core innovation lies in blurring the self-attention weights using a Gaussian filter.

To understand the impact, imagine the diffusion model is navigating a complex, noisy terrain to find the perfect image. This terrain is the "energy landscape." Traditional guidance forces the model to take aggressive steps, often causing it to jump wildly (high curvature), resulting in artifacts. SEG's blurring operation mathematically reduces the curvature of this landscape, effectively smoothing the terrain. This controlled smoothing allows the model to make more measured, coherent updates, resulting in higher-quality samples without the structural trade-offs seen in previous unconditional guidance attempts, such as Self-Attention Guidance (SAG) or Perturbed Attention Guidance (PAG).

Practically, SEG offers flexible quality control. Instead of relying on a guidance scale parameter (which often leads to saturation when increased), SEG uses the standard deviation ($\sigma$) of the Gaussian blur kernel. Increasing $\sigma$ deepens the effect of the smoothing, driving the image quality higher without introducing saturation. The technique validates this control through extreme cases: when $\sigma$ approaches zero, the result is the original, unguided image, while when $\sigma$ approaches infinity, the attention weights become uniform, yielding maximum definition.

The researchers also introduced an efficient "query blurring" method, which achieves the same smoothing effect as blurring the entire attention weights but avoids the computationally expensive quadratic complexity that scales with the number of image tokens.

Quantitative and qualitative comparisons using the Stable Diffusion XL (SDXL) baseline demonstrate significant gains. In unconditional generation tests, SEG achieved a Pareto improvement, resulting in better image quality (lower FID scores) while maintaining a perceptual similarity (LPIPS scores) comparable to the original vanilla SDXL output, implying minimal unintended side effects. For instance, in ControlNet tests, SEG enhanced the structural fidelity and visual quality of images generated from Canny and depth maps, preserving the conditioning signals while adding definition.

By providing a robust, theory-backed method to guide diffusion models universally—even without text conditions—SEG marks a significant step toward improving the flexibility and output quality of foundation generative models.