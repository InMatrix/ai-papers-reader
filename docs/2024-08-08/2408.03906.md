---
layout: paper
pdf_url: https://arxiv.org/pdf/2408.03906
permalink: 2024-08-08/2408.03906/
title: Learned Robot Agent Achieves Amateur Human Level in Competitive Table Tennis
---



In a significant milestone for human-robot interaction and control systems, researchers have developed the first learned robotic agent capable of playing competitive table tennis at an amateur human level against a diverse range of unseen opponents.

The new agent, detailed in a recent paper, uses a highly structured approach to master table tennis—a dynamic sport requiring high-speed precision, complex strategies, and instantaneous adaptation to spin and trajectory. During a comprehensive user study involving 29 human players across various skill levels, the robot proved capable of winning 100% of matches against beginners and 55% against intermediate players, demonstrating a proficiency comparable to a human intermediate player.

Instead of relying on a single, monolithic control program, the researchers implemented a hierarchical and modular policy architecture that mirrors human learning. At the foundation are specialized **Low-Level Controllers (LLCs)**, which are individual physical skills trained efficiently in simulation. Examples of these skills include *forehand topspin*, *backhand targeting*, and *underspin serves*. The final system leverages 17 such LLCs, providing a diverse library of actions.

Orchestrating these physical skills is the **High-Level Controller (HLC)**, the robot's strategic brain. The HLC analyzes the current ball state (position, speed, spin) and opponent statistics in real-time. Crucially, the HLC also tracks its own capabilities via "skill descriptors"—metadata estimating the success rate and resulting ball trajectory for each LLC.

The system's adaptability relies on online preference learning. As the robot plays, the HLC continuously updates its numerical preferences (H-values) for different LLCs based on their real-world performance against that specific opponent. This allows the robot to rapidly adapt its strategy, for example, prioritizing returns that exploit a human player’s known weakness in returning backhand shots.

Achieving this performance required solving the notorious "sim-to-real" gap. The team pioneered a hybrid training method that iteratively grounds simulated learning in real-world data. They collected actual human-human play data to define realistic training task distributions, minimizing the training time spent on unrealistic ball trajectories. They also invested heavily in accurate physics modeling, including a novel "spin correction" phase in simulation to ensure specialized skills, like handling topspin, transferred flawlessly to the physical hardware.

While highly effective, the robot still exhibits vulnerabilities that advanced human players exploit. It struggles with extreme underspin balls, where its return rate drops to 50%, and very fast shots, primarily due to inherent system latency. Furthermore, balls hit very low and close to the net are often missed due to safety-mandated collision avoidance protocols.

Despite these limits, players described the experience of competing against the robot as "fun" and "engaging." This work not only sets a new benchmark for robotic sports but also offers a template for developing robust, adaptive, and safe generalist robots capable of performing complex, real-world tasks alongside humans.