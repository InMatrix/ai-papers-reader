---
layout: paper
pdf_url: https://arxiv.org/pdf/2408.03910
permalink: 2024-08-08/2408.03910/
title: CODEXGRAPH Bridges LLMs and Code Repositories with Graph Databases
---



A new system called CODEXGRAPH is dramatically improving the ability of Large Language Models (LLMs) to interact with complex, real-world software projects. Developed by researchers from the National University of Singapore, Xi'an Jiaotong University, and Alibaba Group, the system solves a long-standing challenge: LLMs excel at stand-alone coding tasks, but struggle when handling vast, interdependent code repositories.

Current retrieval methods used by LLMs—primarily similarity-based searches—often lack the precision needed for structural queries, leading to poor recall in complex, multi-file tasks. CODEXGRAPH bypasses this limitation by converting entire codebases into a specialized **Code Graph Database**, allowing LLM agents to navigate code structures with efficiency and precision.

### Code as a Navigable Network

CODEXGRAPH uses static analysis to index a repository, mapping elements like classes, functions, and modules as "nodes." The relationships between these elements—such as one class inheriting from another (`INHERITS`), or a function utilizing a global variable (`USES`)—are mapped as "edges."

This structure allows the LLM agent to think of the codebase not as a pile of text documents, but as a map where structural relationships are explicit.

When a developer poses a question or task, the LLM agent translates this request into a formal graph query language (like Cypher for the Neo4j database used in the study).

For instance, instead of asking, "Find every mention of the `TaskManager` class," the LLM can precisely query, "Find all methods belonging to the `TaskManager` class, and identify the base class it inherits from, and list all the fields they contain." This multi-hop reasoning is nearly impossible with conventional text retrieval.

### Intuition in Action: Debugging

The power of the graph approach is most evident in complex tasks like debugging. In one example provided by the researchers, the system addresses a reported bug where a function to retrieve LLM token usage was returning an empty dictionary.

The CODEXGRAPH agent didn't guess; it initiated an iterative search:
1. It queried the graph to retrieve the code for the failing method (`_chat_no_stream`).
2. It found the method called an internal utility (`stat_last_call_token_info`).
3. It queried the graph for the code of that utility function, revealing an `AttributeError` handling path that incorrectly updated the usage information.

By chaining precise, structural queries, the LLM agent was able to trace the logical flow across multiple functions and files to pinpoint the exact line responsible for the bug, subsequently generating a precise fix.

### Competitive Performance and Versatility

The system was evaluated against three major repository-level benchmarks: CrossCodeEval, SWE-bench (for GitHub issue resolution), and EvoCodeBench.

CODEXGRAPH demonstrated competitive, often superior, performance compared to existing Retrieval-Augmented Code Generation (RACG) methods, particularly excelling when paired with advanced models like GPT-4o.

Beyond benchmarks, the researchers developed five real-world agents leveraging CODEXGRAPH's capabilities: **Code Debugger**, **Code Commentor** (to generate accurate documentation based on structural understanding), **Code Chat** (for structural inquiries), **Code Unittestor**, and **Code Generator**.

The new approach offers a versatile, structure-aware interface that significantly enhances the generalizability and accuracy of LLMs in automated software development environments, opening the door for more sophisticated AI collaboration in large codebases.