---
layout: paper
pdf_url: https://arxiv.org/pdf/2407.10718
permalink: 2024-07-19/2407.10718/
title: Simple Agent Framework, Sibyl, Achieves State-of-the-Art in Complex AI Reasoning
---



A team of researchers has unveiled "Sibyl," a new large language model (LLM) agent framework designed to tackle complex, multi-step reasoning tasks that have traditionally stymied AI systems. By drawing inspiration from human cognitive theories—specifically the Global Workspace Theory and the Society of Mind Theory—Sibyl dramatically simplifies its internal architecture while boosting reliability in long-term problem-solving.

Existing LLM-based agents often fail in complex, real-world scenarios—tasks requiring dozens of steps to solve—due to two major issues: system complexity and "context dilution." As agents gather information (e.g., browsing the web or running code), they append massive amounts of raw data to their memory, overwhelming the LLM and causing error propagation.

Sibyl addresses this by fundamentally restructuring how agents think and remember.

The framework, instantiated using GPT-4, relies on four core modules, prioritizing simplicity and efficiency. Critically, Sibyl moves away from stateful "dialogue" between components, instead using stateless, reusable Question-Answering functions inspired by functional programming.

### Harnessing Cognitive Architecture

The first major innovation is the **Global Workspace**, acting as a shared, structured memory hub. This component leverages "selective compression," transforming bulky external information into concise, incremental facts.

To build intuition, consider a complex query requiring the agent to search through a dozen webpages and analyze an excel sheet to find a specific financial figure. Traditional agents might append the entire text of every webpage and the raw spreadsheet data to the memory. Sibyl’s Global Workspace, however, extracts and records only the necessary details—the final number, its source, and the URL—discarding the bulk of irrelevant text, thereby eliminating context dilution.

The second key innovation is the **Multi-agent Debate-based Jury**. Inspired by Marvin Minsky’s Society of Mind theory, this module ensures self-correction before providing a final answer. A designated "Actor" agent proposes a solution and detailed thought process, while a "Critic" agent rigorously reviews the logic to identify intellectual or logical errors. This self-refinement process, combined with a majority vote ensemble method, significantly enhances stability and accuracy.

### Benchmark Success

The researchers evaluated Sibyl on the GAIA benchmark, a challenging dataset of real-world questions specifically designed to test the depth and robustness of AI reasoning.

Sibyl achieved a state-of-the-art overall average score of 34.55% on the GAIA test set using the GPT-4 model, significantly outperforming prior leading frameworks like AutoGen and AutoGPT. The improvements were particularly notable in the most difficult Level 2 and Level 3 reasoning tasks.

Moreover, Sibyl demonstrated superior efficiency. For problems where the agent achieved a correct answer, Sibyl required an average of just 4.42 steps, compared to the 6.83 steps typically needed by human solvers.

This efficiency underscores the framework’s ability to transition LLMs from rapid, intuitive "System-1" thinking towards the slow, deliberate, and error-mitigating "System-2" reasoning necessary for complex real-world applications. The design philosophy, emphasizing simplicity and modularity, promises easier integration and debugging, paving the way for more reliable LLM-based agent solutions in the future.