---
layout: paper
pdf_url: https://arxiv.org/pdf/2407.10817
permalink: 2024-07-19/2407.10817/
title: Foundational Autoraters&#58; New Open-Source LLM Judges Outperform GPT-4 and
  Claude-3 on Key Evaluation Benchmarks
---



In the rapidly evolving world of Large Language Models (LLMs), reliable evaluation remains one of the greatest challenges. Traditional human assessment is costly, slow, and prone to subjectivity. While the industry has increasingly relied on "LLM-as-a-Judge" models like GPT-4, these proprietary evaluators are opaque and often suffer from inherent biases.

Now, researchers from Google DeepMind have introduced FLAMe (Foundational Large Autorater Models), a new family of models designed to deliver transparent, generalized, and high-performing automatic evaluation. Remarkably, FLAMe variants, trained exclusively on publicly licensed human data, outperform leading proprietary LLMs across a majority of evaluation benchmarks.

### Taming the Judge with Public Data

The core innovation behind FLAMe is its training regimen. Unlike proprietary models which often use private data or self-generated evaluations, FLAMe was trained on the "FLAMe Collection," a massive, standardized dataset encompassing over 5 million human judgments across 102 diverse quality assessment tasks.

These tasks cover the full spectrum of LLM capabilities, including factuality, safety, reasoning, coding, and general response quality.

To achieve superior generalization, the researchers converted all these diverse tasks—from rating helpfulness on a Likert scale to classifying factual attribution (Yes/No)—into a unified text-to-text format.

For instance, rather than simply receiving a raw score, FLAMe might be prompted with: **INSTRUCTIONS:** *Evaluate whether the summary is attributable to the source article. Answer 'Yes' or 'No', provide an explanation.* The model is trained to output the exact human judgment, such as: **EVALUATION:** *answer: No, explanation: The detail that X is not in the article.* This supervised approach grounds the model in explicit human evaluation criteria.

### Setting New Performance Standards

FLAMe’s performance demonstrates the power of this large-scale, generalized training. Across 12 popular autorater evaluation benchmarks—including the critical RewardBench and LLM-AggreFact—FLAMe variants outperformed all tested proprietary LLM-as-a-Judge baselines on eight of them.

Specifically, the fine-tuned version, FLAMe-RM-24B, achieved an overall accuracy of 87.8% on RewardBench (a benchmark assessing reward models), making it the top-performing generative model trained entirely on permissively licensed data. In comparison, GPT-4-0125 scored 85.9%, and the current flagship model, GPT-4o, scored 84.7%.

Beyond raw performance, the study highlighted significant advancements in efficiency and fairness. The researchers introduced a computationally efficient variant, FLAMe-Opt-RM, which uses a novel "tail-patch" fine-tuning strategy to achieve competitive performance (87.0% on RewardBench) while requiring approximately 25 times less training data points than the full model.

### Less Bias, Greater Utility

A common criticism of proprietary LLM judges is their cognitive bias—a preference for specific styles of answers. For example, some models might subconsciously favor longer responses, or rate an answer higher if it is presented first in a pair (order bias).

The team rigorously tested FLAMe on the CoBBLEr bias benchmark and found that FLAMe variants exhibited significantly less bias compared to models like GPT-4. By training on a diverse set of explicit human judgments, FLAMe is more robust to irrelevant context, response length, and positional ordering.

This reliable evaluation capability has direct practical applications, such as improving generative AI outputs. For example, when used as a re-ranker on the HumanEval Python programming benchmark, FLAMe was able to examine multiple generated code solutions and select the optimal one, improving the success rate of a weaker model by nearly 10 percentage points.

The launch of FLAMe offers a more transparent and unbiased tool for the AI community, demonstrating that foundational autoraters can achieve state-of-the-art results using exclusively open-source, human-labeled data.