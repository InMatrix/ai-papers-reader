---
layout: paper
pdf_url: https://arxiv.org/pdf/2510.22768
permalink: 2025-10-31/2510.22768/
title: MMPERSUADE&#58; A New Framework to Understand How AI Models Are Persuaded
---



**A groundbreaking dataset and evaluation framework called MMPERSUADE are set to illuminate how Large Vision-Language Models (LVLMs) are influenced by persuasive content, especially when it combines text with images and videos.** Researchers from UCLA and Salesforce AI Research have developed this system to address a critical gap in understanding AI's susceptibility to persuasion, a growing concern as these models are increasingly integrated into daily life.

The MMPERSUADE framework tackles the complex question of how LVLMs, as "persuadees," process and respond to persuasive multimodal inputs. The researchers highlight that overly persuadable AI could lead to problematic outcomes, such as adopting misinformation, disregarding user preferences, or generating unsafe content.

**Key Contributions of MMPERSUADE:**

*   **A Comprehensive Multimodal Dataset:** This dataset comprises 450 scenarios, including 62,160 images and 4,756 videos. It covers three distinct persuasion contexts: commercial (e.g., advertising), subjective/behavioral (e.g., health nudges, political messaging), and adversarial (e.g., misinformation). The dataset is built upon established persuasion principles, including Cialdini's six principles of persuasion and Aristotle's three rhetorical appeals.
*   **An Evaluation Framework:** MMPERSUADE quantifies persuasion effectiveness and model susceptibility through two methods: "agreement scoring" (measuring explicit verbal agreement) and "self-estimated token probabilities" (gauging implicit belief). These methods provide a nuanced understanding of how AI's expressed stance and underlying conviction shift.
*   **Three Core Insights from LVLM Experiments:**
    1.  **Multimodality Amplifies Persuasion:** The study found that combining visual elements (images, videos) with text significantly increases persuasion effectiveness and AI susceptibility compared to text alone. This effect is particularly pronounced in misinformation scenarios. For instance, an LVLM might be more easily swayed by a product advertisement featuring an appealing image alongside persuasive text than by the text alone.
    2.  **Prior Preferences Offer Some Resistance, but Multimodality Cushions the Impact:** LVLMs with pre-existing preferences (modeled as "stubbornness") showed reduced susceptibility to persuasion. However, multimodal inputs helped to buffer this decline, suggesting that rich visual cues can maintain persuasive advantage even when the AI has a set initial stance.
    3.  **Strategy Effectiveness Varies by Context:** Different persuasive strategies proved more effective in different contexts. Reciprocity and consistency were particularly potent in commercial and subjective persuasion, while credibility and logic-based appeals were more successful in adversarial situations. For example, a commercial appeal emphasizing a "buy one, get one free" offer (reciprocity) might work well, whereas an attempt to spread misinformation would be better countered with appeals to logic and evidence.

The research team evaluated six leading LVLMs using the MMPERSUADE framework. Their findings underscore the growing need to develop AI models that are not only capable of understanding multimodal content but also robust, preference-consistent, and ethically aligned when encountering persuasive messages. This work lays crucial groundwork for building safer and more responsible AI systems.