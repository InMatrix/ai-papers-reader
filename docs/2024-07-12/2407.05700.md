---
layout: paper
pdf_url: https://arxiv.org/pdf/2407.05700
permalink: 2024-07-12/2407.05700/
title: Code LLMs Learn to Improve Themselves by “Thinking Backward”
---



A new self-improvement strategy called Inverse-Instruct is enabling open-source large language models (LLMs) specialized in coding to dramatically enhance their performance without relying on expensive, proprietary models like GPT-4.

Developed by researchers from the Institute of Computing Technology (CAS) and Baidu Inc., the methodology flips the traditional instruction-tuning process on its head, leveraging an overlooked asymmetry in how LLMs process code and natural language. The resulting models, dubbed InverseCoder, are setting new state-of-the-art benchmarks among publicly available code LLMs, demonstrating a pathway toward sustainable, low-cost AI development.

### The Code-to-NL Advantage

For years, the development of high-performing open-source code LLMs required a costly step: generating instruction-code pairs by querying stronger closed-source models (NL-to-Code). Inverse-Instruct circumvents this cost by recognizing a critical insight validated by the research team: code LLMs are inherently much better at translating *code into instructions* (Code-to-NL) than translating *instructions into code* (NL-to-Code).

This finding means that instead of asking a model to generate new solutions to new problems, Inverse-Instruct asks the model to look at existing, high-quality code responses in its training set and figure out the natural language prompt that could have created them.

“A single code snippet can serve as a valid response to multiple instructions,” the researchers note. By reversing the process (Code Summarization), the model can self-generate diverse, new natural language prompts that map back to the high-quality code it already knows how to produce.

### How Inverse-Instruct Works

The Inverse-Instruct process consists of three stages:

1.  **Code Preprocessing:** Clean code snippets are extracted from the original instruction-tuning dataset.
2.  **Code Summarization:** The code LLM itself is prompted to generate multiple candidate instructions based on the cleaned code.
3.  **Self-Evaluation and Selection:** The LLM evaluates these self-generated instructions and selects the best one by using a proprietary "pseudo-probability" score—effectively gauging which instruction is most likely to correctly produce that exact code snippet again.

For instance, if the LLM encounters a common Python script—such as one that uses the `os` module to list files in a directory—it can be prompted to generate several instructions, like, "Write a Python function to traverse the current directory," or "Create a simple Python script that lists all the files." By scoring these candidates, the best instruction-code pair is added to the training set, augmenting the model's knowledge base.

### SOTA Results at Lower Cost

The InverseCoder series, fine-tuned using this self-generated data, showed substantial gains across major coding benchmarks. InverseCoder, based on the DeepSeek-Coder-6.7B model, achieved a Pass@1 score of 79.9% on HumanEval(+) and 78.6% on MBPP(+)—metrics that surpass all comparable open-source models. The self-improvement strategy was effective not just for general Python coding, but also for multilingual tasks (across Java, C++, Swift, and Rust) and specialized data science code generation using libraries like Pandas and PyTorch.

Crucially, the new approach relies only on the cost of running the open-source model itself for data generation, offering a highly economical alternative to purchasing data from proprietary LLM providers. By leveraging the superior Code-to-NL ability, InverseCoder marks a significant step toward developing powerful, transparent, and self-sufficient code intelligence tools.