---
layout: paper
pdf_url: https://arxiv.org/pdf/2508.13167
permalink: 2025-08-22/2508.13167/
title: New Approach Boosts AI Agent Capabilities with Chain-of-Agents Paradigm
---



Researchers at OPPO AI have introduced a groundbreaking new paradigm for artificial intelligence agents called "Chain-of-Agents" (CoA). This innovative approach aims to overcome the limitations of existing multi-agent systems, which often suffer from high computational overhead and difficulties in adapting to new tasks. The CoA paradigm enables a single, unified model to perform complex, multi-turn problem-solving, mimicking the collaborative capabilities of multiple specialized agents without the need for complex external frameworks or manual prompt engineering.

Traditional multi-agent systems typically rely on sophisticated orchestration and prompt engineering to guide interactions between different agents. This can lead to inefficiency and challenges in generalizing to novel scenarios. The CoA approach, however, integrates various "role-playing" and "tool-using" agents within a single, end-to-end trainable model. This allows the model to dynamically activate the most appropriate agents and tools as needed, streamlining the problem-solving process.

To develop these advanced agents, the OPPO team introduced a novel "multi-agent distillation" framework. This process effectively distills the decision-making patterns and collaborative strategies of state-of-the-art multi-agent systems into the CoA framework. Following distillation, the models undergo "agentic reinforcement learning" on verifiable tasks to further refine their problem-solving abilities. The resulting models are dubbed "Agent Foundation Models" (AFMs).

The researchers demonstrated the effectiveness of AFMs across a range of benchmarks, including web agent and code agent tasks. Their empirical studies show that AFMs achieve new state-of-the-art performance on several challenging benchmarks. For instance, on the GAIA benchmark, AFMs achieved a score of 55.3%, significantly outperforming previous methods. Similarly, on the BrowseComp and HLE benchmarks, AFMs showed marked improvements, with scores of 11.1% and 18.0% respectively. In code generation and mathematical reasoning tasks, AFMs also exhibited substantial gains, outperforming existing tool-integrated reasoning methods.

A key advantage highlighted in the paper is the computational efficiency of the CoA paradigm. The research indicates that AFMs reduce inference costs by an impressive 84.6% compared to traditional multi-agent systems, while maintaining competitive performance. This efficiency stems from the elimination of redundant communication between agents and a more streamlined data construction mechanism that filters out irrelevant information.

The researchers have made their entire research, including model weights, training code, and data, fully open-source. This move is intended to provide a strong foundation for future research in agent models and agentic reinforcement learning, fostering further advancements in the field.