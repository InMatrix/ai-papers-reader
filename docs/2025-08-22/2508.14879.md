---
layout: paper
pdf_url: https://arxiv.org/pdf/2508.14879
permalink: 2025-08-22/2508.14879/
title: MeshCoder&#58; LLM-Powered Structured Mesh Code Generation from Point Clouds
---



A groundbreaking new framework, MeshCoder, promises to revolutionize 3D object reconstruction by translating raw 3D point cloud data into editable Blender Python scripts. This innovative approach, detailed in a recent paper, leverages the power of large language models (LLMs) and a novel set of expressive Blender Python APIs to achieve highly accurate and versatile 3D shape generation.

Traditionally, reconstructing 3D objects into editable formats has been hampered by limitations in domain-specific languages (DSLs) and the scarcity of large, high-quality datasets. MeshCoder tackles these challenges head-on. The researchers first developed a comprehensive suite of Blender Python APIs capable of creating intricate geometries beyond simple primitives. These APIs allow for sophisticated operations like extruding 2D shapes along trajectories, bridging different shapes, and applying complex boolean operations.

To train their model, MeshCoder’s creators built a massive dataset containing approximately one million 3D objects, each broken down into its constituent parts. For instance, a chair is not just a single entity but is represented as separate code for its legs, seat, and back. This part-based approach is key to MeshCoder’s ability to generate semantically rich code. A large-scale, paired object-code dataset was meticulously constructed by synthesizing diverse object parts and then using a part-to-code inference model to predict the code for each individual component. This process, refined by carefully designed rules for combining these part codes, results in complete object programs.

The core of MeshCoder is a multimodal large language model trained on this extensive dataset. This LLM takes a 3D point cloud as input and autoregressively generates Blender Python scripts. These scripts, when executed, reconstruct the original 3D object with its parts clearly defined. The output code is not only functional but also highly interpretable, with comments detailing the object's name and its individual parts.

MeshCoder’s performance has been rigorously evaluated, demonstrating superior accuracy in shape-to-code reconstruction compared to existing methods. A key advantage highlighted in the paper is the enhanced editability offered by the code-based representation. Users can intuitively modify geometric and topological properties by simply adjusting parameters within the generated Python script. For example, changing a scale parameter could alter the thickness of a chair’s legs, or adjusting resolution parameters could refine the mesh detail of a plate.

Furthermore, MeshCoder’s code-based representation proves beneficial for 3D shape understanding. By inputting the generated code into LLMs like GPT-4, researchers have shown that these models can effectively comprehend object structures and answer specific questions about them, such as identifying the number of wheels on a chair or describing the shape of a dishwasher's handle.

While MeshCoder primarily targets human-made objects, the researchers acknowledge the need for further development to encompass more organic forms. Nevertheless, MeshCoder represents a significant leap forward, offering a powerful and flexible solution for programmatic 3D shape reconstruction and editing, with broad implications for fields like reverse engineering and computer-aided design.