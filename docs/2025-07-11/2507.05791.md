---
layout: paper
pdf_url: https://arxiv.org/pdf/2507.05791
permalink: 2025-07-11/2507.05791/
title: AI Agent Masters Complex Interfaces with Smarter Planning and Grounding
---



**San Francisco, CA – July 11, 2025** – Navigating the intricacies of graphical user interfaces (GUIs) is a cornerstone of advancing artificial intelligence towards more human-like capabilities. However, current GUI agents often struggle with two key challenges: ambiguity in planning multiple interaction steps and precisely "grounding" actions to the correct visual elements on high-resolution, complex screens. A new paper from Salesforce AI Research introduces **GTA1 (GUI Test-time Scaling Agent)**, a novel approach that tackles these hurdles head-on, demonstrating state-of-the-art performance in both grounding accuracy and overall task completion.

At the heart of GTA1 are two main innovations. Firstly, the agent employs a **test-time scaling strategy for planning**. Instead of committing to a single, pre-determined sequence of actions, GTA1 samples multiple potential action proposals at each step. A sophisticated "judge" model, often a multimodal large language model, then evaluates these options based on the current task and interface state, selecting the most appropriate one. This allows the agent to intelligently navigate ambiguous situations and avoid the pitfalls of a single flawed plan. For instance, if a user wants to book a flight, and the agent needs to input a destination, instead of blindly attempting to type into a specific field, GTA1 might propose several ways to initiate the destination input, letting the judge model pick the most contextually relevant one.

Secondly, GTA1 introduces a streamlined approach to **visual grounding**. Traditional methods often rely on complex "thinking" or reasoning processes before predicting an interaction point. GTA1, however, leverages Reinforcement Learning (RL) to directly predict interaction coordinates, rewarding the agent for successfully clicking on the correct target element. This is a significant departure, as it aligns the training objective directly with the task itself. Imagine an agent trying to click a "Submit" button. Instead of the agent first generating a textual plan like "I need to click the submit button," GTA1's grounding model is trained to directly predict the button's location, with the reward coming from whether that predicted spot falls within the button's boundaries.

The paper showcases GTA1's impressive capabilities across several benchmarks. On the challenging ScreenSpot-Pro dataset, which features professional interfaces, GTA1 achieved up to 50.1% accuracy. For web and desktop interactions, it attained 92.4% accuracy on ScreenSpot-V2. Crucially, when evaluated on the OSWorld benchmark, which simulates real-world Linux environments, GTA1 demonstrated a task success rate of 45.2%, outperforming existing state-of-the-art agents, even those with longer execution horizons.

A key experimental finding highlights that while "thinking" can be beneficial in highly dynamic or complex scenarios, GTA1's direct RL-based grounding is generally more efficient and robust for typical GUI interactions. The researchers also demonstrated the scalability of their test-time scaling strategy, showing that even with fewer steps, GTA1, when using a wider range of sampled actions (higher K), could outperform baseline methods that executed many more steps without this strategy.

By addressing both planning ambiguity and grounding precision, GTA1 represents a significant step towards more capable and reliable AI agents that can seamlessly interact with the visual world, opening doors for more sophisticated automation and user assistance.