---
layout: paper
pdf_url: https://arxiv.org/pdf/2512.24551
permalink: 2026-01-02/2512.24551/
title: New AI Model Learns Physics, Eliminating Glitches in Text-to-Video Generation
---



A team of researchers from Meta Superintelligence Labs and Johns Hopkins University have unveiled a new framework for training text-to-video (T2V) models that significantly improves physical consistency, addressing a major shortcoming of current leading generative AI.

The new system, dubbed PhyGDPO (Physics-Aware Groupwise Direct Preference Optimization), tackles the persistent problem where visually stunning models like OpenAI’s Sora or Google’s Veo often generate videos that defy basic physics—such as a basketball floating through a hoop or objects lacking realistic material interactions.

PhyGDPO achieves this leap in physical reasoning through a three-pronged approach: superior physics-rich training data, an advanced preference optimization algorithm, and an explicit physics-guided reward system.

### Training the Model on Real-World Laws

The first challenge in teaching AI physics is the lack of comprehensive, physically annotated training data. To solve this, the researchers developed the Physics-Augmented video data construction Pipeline (PhyAugPipe). This pipeline employs a Vision-Language Model (VLM) with "Chain-of-Thought" reasoning to analyze vast datasets of text-video pairs. The VLM doesn't just look at the video; it explicitly reasons about the entities, forces, and outcomes—filtering out millions of weak examples and creating a new high-quality dataset, PhyVidGen-135K, rich in physical interactions.

For instance, the VLM might be asked to evaluate a video of a baseball bat smashing a glass bottle. PhyAugPipe ensures the retained data shows realistic material deformation and shatters, rather than generating an implausible outcome where the bottle remains intact.

### Groupwise Optimization and Explicit Rewards

Standard preference training (known as DPO) uses simple binary comparisons (Video A is better than Video B). PhyGDPO moves to a more holistic approach using Groupwise Direct Preference Optimization (GDPO), which assesses a ranked *list* of generated videos simultaneously. This allows the model to capture broader preference signals, such as overall smoothness and physical plausibility, rather than just isolated pairwise judgments.

Crucially, the team introduced a Physics-Guided Rewarding (PGR) scheme. Instead of relying solely on the T2V model itself to judge physics (which it’s bad at), PGR leverages an external, physics-aware VLM to explicitly score videos for physical commonsense and semantics adherence. This system heavily penalizes videos that violate physical laws, such as one showing a tennis ball floating on water without adhering to fluid buoyancy.

To make this complex training feasible, the team integrated a specialized mechanism called LoRA-Switch Reference (LoRA-SR), which dramatically cuts down on GPU memory usage and stabilizes training by sharing the heavy backbone of the model between the trainable version and the fixed reference version.

Through extensive testing on challenging benchmarks like PhyGenBench and VideoPhy2, PhyGDPO significantly outperformed state-of-the-art open-source and commercial models. In user studies, human evaluators showed a strong preference for PhyGDPO videos, noting their superior realism in complex actions like gymnastics, squash, and accurate physical phenomena such as light refraction and combustion.