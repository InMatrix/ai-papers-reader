---
layout: paper
pdf_url: https://arxiv.org/pdf/2503.13553
permalink: 2025-03-21/2503.13553/
title: LLMs Guide Multi-Agent Systems to Fight Wildfires More Effectively
---


**Integrating large language models (LLMs) into multi-agent reinforcement learning (MARL) systems can significantly improve their performance in complex environments, such as aerial wildfire suppression, according to a new study.** Researchers at Aleph Alpha Research and Google DeepMind have demonstrated that LLMs can guide agents toward more desirable behaviors, leading to more efficient training and better overall performance.

The study focused on an Aerial Wildfire Suppression (AWS) environment within the HIVEX suite, where multiple agents (simulated aircraft) work together to extinguish wildfires. The challenge lies in the dynamic and unpredictable nature of fire spread, influenced by factors like wind direction, humidity, and terrain, all while the agents need to cooperate.

To facilitate LLM-driven guidance, the researchers implemented two types of "controllers" that provide interventions during the training process:

1.  **Natural Language (NL) Controller:**  This controller uses an LLM to simulate human-like interventions. For example, imagine a human operator saying, "Agent 2, go to the top center; Agent 0, go to the bottom left." The LLM translates these high-level instructions into specific actions for the agents. The researchers used both the Pharia-1-LLM-7B-control-aligned and Llama-3.1-8B Instruct LLMs for this.
2.  **Rule-Based (RB) Controller:**  This controller uses predefined rules to generate interventions. For instance, it might instruct agents to go to their closest fire.

These interventions are passed to an "LLM-Mediator," which temporarily overrides the agents' learned policies with actions derived from the controller's instructions.

The researchers compared the performance of MARL agents trained with these controllers against a baseline without any interventions. The results showed that both the NL and RB Controllers significantly outperformed the baseline.

"Our findings indicate that agents particularly benefit from early interventions, leading to more efficient training and higher performance," said Philipp Siedler, a researcher at Aleph Alpha Research and one of the paper's authors. The NL Controller, simulating more complex and context-aware human guidance, had a stronger impact than the RB Controller. One example of why early interventions help is that early guidance in the right direction avoids the agents going down a wrong path and wasting resources and time on a learning trajectory that proves to be unhelpful.

The study also explored the scalability of the approach by varying the number of agents in the AWS environment. The results suggest that while performance improves with LLM-mediated interventions, coordination challenges can emerge as the number of agents increases.

The research highlights the potential of integrating LLMs with MARL to tackle complex, real-world problems. It provides a pathway towards more efficient training and enhanced performance of multi-agent systems, with applications extending beyond wildfire suppression to areas like robotics and resource management. The researchers also acknowledge that further studies are needed to validate their findings in more realistic environments and across different domains.