---
layout: paper
pdf_url: https://arxiv.org/pdf/2406.12045
permalink: 2024-06-21/2406.12045/
title: New Benchmark Exposes Fragility of State-of-the-Art AI Customer Service Agents
---



**WASHINGTON D.C.**—A new benchmark designed to test the trustworthiness and consistency of language agents in complex, real-world scenarios reveals that even the most advanced AI models are severely unprepared for deployment in high-stakes environments like customer service.

Researchers have introduced T-bench (Tool-Agent-User Interaction Benchmark), a system that simulates dynamic conversations between an AI agent, its domain-specific API tools, and a user simulated by a separate language model. Crucially, T-bench forces the agents to navigate complex, ad-hoc policy documents—a critical requirement for any operational AI in finance, healthcare, or retail—while interacting conversationally.

The results are striking. State-of-the-art function-calling models, including OpenAI’s flagship GPT-4o, achieved average success rates (Pass@1) of only 61% on the T-retail domain (handling product returns and exchanges) and a mere 35% on the more complex T-airline domain (managing flight bookings and cancellations).

### Consistency is the Core Challenge

The researchers developed a new metric, $pass^k$, to measure consistency and robustness by testing if an agent can successfully complete the same task $k$ independent times. If an agent achieves a high Pass@1 score, it means it gets the task right once on average. A high $pass^k$ score means it is reliable.

Intuition into the agent's fragility is stark when looking at $pass^8$. For GPT-4o, the chance of consistently solving a T-retail task across eight trials dropped to below 25%. This extreme drop highlights that current agents are brittle when faced with the stochastic variations common in natural human dialogue, failing to stick to policies reliably.

T-bench introduces two realistic customer service domains: **T-retail**, which involves tasks like canceling pending orders or exchanging delivered goods, and **T-airline**, which includes complex constraints regarding flight changes, baggage allowances tied to membership tiers, and refund rules.

For example, in a T-airline task, a user might try to change a "basic economy" flight. The agent must first consult the domain policy document, which explicitly prohibits modification of basic economy tickets. The agent must then demonstrate proactive reasoning by suggesting an alternative, such as canceling the original ticket (if within the 24-hour window) and rebooking, while correctly calculating refunds based on the user's payment methods.

### Failure Modes Highlight Need for Better Reasoning

Analysis of the failures points to three primary weaknesses in current agents. First, agents struggle with complex database reasoning, often producing "wrong arguments" for API calls or providing "wrong information" to the user, like calculating an incorrect price difference for an exchange.

Second, agents often exhibit "incorrect decision-making" by failing to understand and adhere to domain rules. For instance, in T-retail, a policy might state that an agent can only issue one exchange action per order. Agents frequently ignore this rule, attempting to exchange one item, succeeding, and then trying to exchange a second item, resulting in an error.

The introduction of T-bench is intended to spur the development of more trustworthy agents capable of robustly handling both multi-step dialogue and complex policy adherence, paving the way for reliable AI deployment in automated customer interactions.