---
layout: paper
pdf_url: https://arxiv.org/pdf/2406.11931
permalink: 2024-06-21/2406.11931/
title: Open-Source AI Challenger DeepSeek-Coder-V2 Rises, Matching GPT-4 Turbo in
  Code and Math
---



In a major advance for the open-source artificial intelligence community, DeepSeek-AI has unveiled DeepSeek-Coder-V2, a new Mixture-of-Experts (MoE) language model series that achieves performance on par with, and in some cases superior to, top closed-source leaders like GPT-4 Turbo and Claude 3 Opus in coding and mathematical reasoning tasks.

DeepSeek-Coder-V2, available under a permissive license, is positioned as the most capable open-source code intelligence model to date, having been rigorously pre-trained on an enormous 10.2 trillion tokens. This training set is heavily weighted toward technical data, comprising 60% source code and 10% mathematical corpus, enabling its dramatic leap in specialized reasoning.

The new series, which includes a flagship model with 236 billion total parameters (21 billion active parameters), significantly expands its scope, supporting an unprecedented 338 programming languages—up from 86 in its predecessor. Furthermore, it addresses a key industry need by extending its maximum context length eightfold, from 16K to 128K tokens. This means developers can feed the model massive projects, equivalent to about 100,000 lines of standard code, for tasks like refactoring or debugging.

### Breaking Benchmark Records

DeepSeek-Coder-V2 has set new open-source standards across critical benchmarks, often besting its commercial rivals.

In foundational code generation tests like HumanEval (Python), the model achieved an accuracy of 90.2%. More impressively, it demonstrated robust problem-solving skills in competitive programming. When evaluated on LiveCodeBench—a challenging dataset mirroring real-world coding competitions—DeepSeek-Coder-V2 tied the formidable GPT-4o with an overall score of 43.4%, establishing itself as a top contender in handling complex, novel coding challenges.

Its prowess is not limited to software. On advanced mathematical reasoning benchmarks, DeepSeek-Coder-V2 achieved 75.7% accuracy on the MATH benchmark, nearly matching the state-of-the-art accuracy of 76.6% set by GPT-4o, and solving more problems from the AIME 2024 competition than any other tested model, closed or open source.

### Practical Performance for Developers

Beyond raw scores, the model introduces practical improvements for everyday coding. The smaller 16B parameter version, DeepSeek-Coder-V2-Lite, was trained using a crucial "Fill-In-the-Middle" (FIM) technique.

This allows the model to deftly complete code when given both the surrounding prefix and suffix. For instance, if a developer writes `def calculate_interest(amount, rate):` followed by the function’s closing lines, the model can accurately fill in the core logic, scoring exceptionally high on infilling tasks (86.4% mean accuracy). This feature is essential for enhancing code editors and integrated development environments (IDEs).

DeepSeek-Coder-V2’s release marks a pivotal moment, narrowing the gap between proprietary and community-driven AI, providing developers worldwide with a state-of-the-art tool capable of complex coding and robust mathematical reasoning. The DeepSeek-AI team notes that future work will focus on improving the model's instruction-following capabilities on highly complex, multi-file software engineering tasks, such as those found in the SWE-Bench.