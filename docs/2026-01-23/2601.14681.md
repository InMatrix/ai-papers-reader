---
layout: paper
pdf_url: https://arxiv.org/pdf/2601.14681
permalink: 2026-01-23/2601.14681/
title: FARE&#58; A New Dual-Brain Architecture Uses LLMs to Revolutionize Robotic
  Exploration
---



Autonomous mobile robots have long struggled to explore large, unknown environments efficiently, often getting caught in cycles of redundant movements or failing to adapt their strategies to changing structural cues. Now, researchers have introduced FARE (Fast-Slow Agentic Robotic Exploration), a novel hierarchical framework that imbues robots with a dual-mode thinking process, mirroring human cognitive architecture to drastically improve mapping efficiency.

FARE is built on the fast-slow thinking paradigm, decoupling long-term strategic reasoning from immediate, sensor-driven local control. This allows the system to exploit high-level environmental semantics—something traditional geometric planners overlook—while maintaining real-time responsiveness.

### The Slow Thinker: Global Strategy

The crucial innovation lies in FARE's “Slow-Thinking Module,” powered by a Large Language Model (LLM). This module takes a concise, natural language description of the environment—for instance, "Forest—outdoor forest environment with natural obstacles, trees, and uneven terrain"—and translates it into an adaptive, agent-level exploration strategy.

The LLM dissects the description into predefined structural dimensions (like 'spatial complexity' and 'navigation difficulty') and then synthesizes a coherent set of long-term objectives, such as "prioritize reliability and path quality over speed" or "increase tolerance for backtracking."

This strategy is then grounded into a sequence of global waypoints overlaid on a sparse, topologically informed graph of the environment. The LLM acts as the master strategist, telling the robot *where* it needs to go next to maintain optimal long-range coverage, avoiding the myopic focus typical of earlier systems.

### The Fast Agent: Local Execution

In contrast, the "Fast-Thinking Module" operates on local sensor data and executes the movements. This module uses a Reinforcement Learning (RL) policy, which must rapidly select actions based on the immediate surroundings, such as local frontiers and nearby obstacles.

The key challenge in integrating these two scales—strategic thought and instantaneous movement—is ensuring coordination. FARE solves this with a specific instruction-following reward function. This mechanism penalizes the RL policy exponentially if it deviates significantly from the LLM-generated global waypoints. This guidance encourages the robot to pursue long-term goals while retaining the flexibility to make local, collision-free maneuvers and exploit nearby informative regions without unnecessarily backtracking or getting stuck in dead ends.

### Efficiency Gains in Complex Terrain

The framework demonstrated substantial improvements in challenging simulated and real-world environments compared to state-of-the-art baselines like TARE and DSVP.

In a dense "Warehouse" environment, characterized by narrow aisles and complex stacking, the adaptability of FARE was particularly evident. The conventional planners struggled with the clutter, resulting in excessive detours. FARE, leveraging its LLM guidance, completed the exploration using only 441 meters of travel distance, significantly less than the 652 meters required by TARE, demonstrating that it systematically incorporates global structural cues to find the most efficient route.

The researchers successfully deployed FARE on an Agilex Scout-mini mobile robot in a large 200m by 130m campus teaching building, validating that the system can perform onboard LLM inference and transfer its simulation-learned efficiency to complex, real-world mapping tasks.

By integrating the semantic understanding of large language models with the geometric precision of reinforcement learning, FARE offers a robust blueprint for future autonomous systems capable of reasoning and operating coherently in dynamically unfolding, complex environments.