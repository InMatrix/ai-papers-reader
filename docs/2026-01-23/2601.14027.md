---
layout: paper
pdf_url: https://arxiv.org/pdf/2601.14027
permalink: 2026-01-23/2601.14027/
title: General AI Coding Agent Achieves State-of-the-Art in Formal Math Proof
---



A team of researchers has introduced Numina-Lean-Agent, a novel agentic system that uses a general-purpose AI coding model to achieve state-of-the-art performance in formal theorem proving, including solving all problems from the highly challenging Putnam 2025 competition.

The breakthrough signals a major shift in how AI-driven mathematical reasoning systems are built. Unlike previous leading systems that relied on complex, specialized models trained solely for formal verification, Numina-Lean-Agent leverages a powerful, general-purpose coding large language model (LLM), specifically Claude Opus 4.5, as its core reasoner. This approach grants the system exceptional flexibility and reproducibility, allowing its performance to be boosted simply by swapping in a more capable base model, without requiring intensive specialized retraining.

The system’s architecture, built around the Numina-Lean-MCP (Model Context Protocol), allows the primary agent to autonomously select and orchestrate a suite of specialized reasoning tools.

For instance, to tackle a proof, the agent interacts directly with the Lean theorem prover via the Lean-LSP-MCP tool, which provides real-time feedback on proof states and compilation errors. If the agent needs to recall existing mathematical definitions, it uses LeanDex, a semantic search engine that intelligently retrieves relevant theorems from Lean’s massive library, Mathlib, using natural language queries.

A key component for long-horizon planning is the Informal Prover, which first generates a detailed, human-readable proof outline. This outline is rigorously checked by a separate Verifier model, and if errors are found, the initial Generator refines the proof iteratively—a feedback loop that proved far more efficient than generating multiple independent solutions.

To handle tactical roadblocks, the system uses a Discussion Partner. If the agent gets stuck trying to apply a complex Lean tactic like `ring` (used for polynomial equations), the Discussion Partner queries an external LLM for strategic advice. For example, if a tactic fails because of denominators, the partner might suggest the agent first apply `field_simp` to clear them, providing a concrete tactical path forward.

On the rigorous Putnam 2025 benchmark, Numina-Lean-Agent successfully formalized all 12 problems, matching the perfect score of the best closed-source system, AxiomProver.

Beyond benchmarks, the system demonstrated its true generality in a complex, sustained human-AI collaboration: formalizing the notoriously difficult Brascamp-Lieb theorem. Over two weeks, the agent worked alongside human mathematicians, autonomously introducing approximately 70 new definitions and lemmas and generating over 8,000 lines of verified Lean code.

During this deep formalization process, the agent exhibited a capability rarely seen in automated provers: the ability to *self-correct* the statement of a theorem. If it encountered a logical inconsistency that suggested the original mathematical statement or definition was slightly wrong or underspecified, the agent could dynamically revise the formulation and continue the proof process. This adaptive planning layer, known as "blueprint generation," is crucial for translating complex, long-horizon mathematical ideas into formally verifiable steps, stabilizing the entire proof workflow.

While the generated proofs are sometimes verbose—a recognized limitation—the Numina-Lean-Agent’s blend of powerful, general-purpose reasoning and specialized tool orchestration establishes a robust new paradigm for automated discovery and verification in formal mathematics.