---
layout: paper
pdf_url: https://arxiv.org/pdf/2512.15374
permalink: 2025-12-19/2512.15374/
title: LLM Agents Learn to Evolve&#58; New Framework SCOPE Enables Real-Time Prompt
  Adaptation
---



A new research paper introduces SCOPE (Self-evolving Context Optimization via Prompt Evolution), a novel framework that allows Large Language Model (LLM) agents to automatically update and optimize their internal instructions based on real-time execution feedback. This mechanism addresses a critical bottleneck in AI agents: their inability to adapt to the complex, dynamic contexts found in modern expert-level tasks.

Traditional LLM agents rely on static, one-size-fits-all prompts, which the researchers found leads to systematic "Corrective" and "Enhancement" failures. By treating the agent’s core instruction set as a dynamic, evolvable parameter, SCOPE dramatically improves reliability, more than doubling task success rates on challenging benchmarks without requiring human intervention.

On the expert-level Humanity's Last Exam (HLE) benchmark, SCOPE raised the task success rate from 14.23% for static agents to 38.64%. On the General AI Assistants (GAIA) benchmark, success jumped from 32.73% to 56.97%.

### Learning from Failure and Success

The core innovation of SCOPE is turning the agent's execution traces—its logs of actions and observations—into a learning signal. When a failure occurs, or even when a success is achieved suboptimally, SCOPE synthesizes a concise, actionable guideline in natural language and integrates it directly into the agent’s prompt.

The researchers identified two primary modes of failure that SCOPE addresses:

1.  **Corrective Failure (Error Repetition):** Static agents often treat error messages as generic alarms, leading to infinite loops. For example, if an agent uses the tool name `final_answer` instead of the correctly defined `final_answer_tool`, the environment returns an error listing valid tools. A static agent retries the wrong name. SCOPE analyzes the trace, synthesizes the rule: "Use 'final\_answer\_tool' not 'final\_answer'," and prevents the loop in the next step.
2.  **Enhancement Failure (Missed Optimization):** Agents often succeed but miss optimization opportunities. When searching for baseball statistics, an agent might only use the keyword "walks." SCOPE analyzes the successful trace and proactively adds a guideline: "Include synonyms: 'base on balls', 'BB' for baseball stats," leading to faster, more robust retrieval in future attempts.

### Dual-Stream Strategy and Exploration

To ensure robustness, SCOPE employs a Dual-Stream Routing mechanism, balancing immediate fixes with long-term principles. Tactical guidelines (like fixing a specific tool name error) are used for the current task only, while strategic guidelines (like general search optimization principles) are consolidated and persist across tasks, becoming part of the agent's evolving "constitution."

Furthermore, SCOPE introduces Perspective-Driven Exploration, running parallel evolution streams guided by distinct optimization priorities, such as "Efficiency" and "Thoroughness."

This perspective divergence is critical for handling complex scenarios. When the agent’s browser encounters a blocked website (HTTP 403 error), the Efficiency stream evolves a "fail-fast" guideline: "If access is blocked, immediately escalate to Search Agent. Do not retry." Meanwhile, the Thoroughness stream learns to be resilient: "If access is blocked, attempt workarounds via Archive.org or Transcript Tools." The system then selects the best outcome from these diverse strategies.

The findings validate a shift away from manual, one-time prompt engineering toward dynamic, self-evolving agents that can adapt to the complexities of real-world tasks step-by-step.