---
layout: paper
pdf_url: https://arxiv.org/pdf/2512.11934
permalink: 2025-12-19/2512.11934/
title: User Reviews Reveal Generative AI’s Dual Impact on E-Teaching, Praising Homework
  Helpers But Criticizing Paywalls
---



A new sentiment-driven evaluation of top AI educational applications (ed-apps) on the Google Play Store shows that while generative AI is strongly embraced for quick, personalized learning, its adoption is hampered by aggressive monetization and technical failures.

The study, conducted by researchers from Islamic Azad University and the University of Isfahan, analyzed thousands of user reviews across 20 leading AI ed-apps—ranging from math solvers to language tutors—to gauge real-world efficacy, challenges, and user satisfaction. Using advanced NLP techniques, including the RoBERTa model for classification and GPT large language models for theme extraction, the analysis found an overall positive sentiment (averaging around 85%), driven largely by efficiency gains.

### Homework Helpers Dominate Satisfaction

The results established a clear hierarchy of satisfaction, with Homework Helpers dominating the positive feedback. These tools average over 80% positive sentiment, excelling in areas vital to student productivity: speed, accuracy, and personalized, step-by-step explanations.

For instance, apps like **Edu AI - Homework Helper** received a staggering 95.9% positive rating, closely followed by **Answer.AI - Your AI tutor** at 92.7%. Users frequently praised these apps for their ability to provide instant, detailed conceptual support, essentially democratizing high-quality academic assistance often unavailable in under-resourced schools.

Conversely, specialized apps like Learning Management Systems (LMS) and Language Learning tools lagged significantly. The lowest performer, **Teacher AI - Language Practice**, registered only 21.8% positive sentiment, facing intense criticism for instability, limited features, poor speech recognition, and reliance on outdated AI models. This suggests that while GenAI performs well in analytical, immediate-answer tasks (like math or science problem-solving), it struggles with nuanced domains requiring high fidelity in real-time interaction.

### The Double-Edged Sword: Paywalls and Inaccuracies

While users celebrate efficiency, the primary source of negative feedback revolves around two central issues: monetization and technical unreliability.

Negatives frequently cited aggressive paywalls and limited free access (seen in apps like Help AI and Quizard AI), intrusive ads (Brainly), and major billing errors. This creates an equity barrier, as powerful AI features are often locked behind subscriptions, potentially widening the digital divide.

Technical flaws further erode trust. Reviewers complained about inaccuracies and incomplete answers, alongside fundamental instabilities like app crashes and unreliable input methods, such as camera scanning (e.g., in Nerd AI).

### A Roadmap for Ethical Transformation

The researchers conclude that for AI to fulfill its transformative potential in e-teaching, developers and policymakers must prioritize ethical refinements.

The study strongly advocates for a shift toward **hybrid AI-human models**, where AI handles routine tasks (like grading and basic explanations), freeing human educators to focus on critical thinking and deeper interaction. For example, integrating high-rated step-by-step explanations (like those from Gauth) with teacher oversight could mitigate risks of over-reliance and plagiarism.

Furthermore, a roadmap is proposed requiring developers to prioritize true adaptive personalization and expanding collaboration features. Policymakers are urged to regulate monetization for inclusivity by mandating expanded free tiers and establishing firm standards for accuracy and data privacy protections, ensuring that the next generation of GenAI ed-apps fosters an equitable and accessible learning environment for all.