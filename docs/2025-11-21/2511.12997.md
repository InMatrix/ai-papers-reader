---
layout: paper
pdf_url: https://arxiv.org/pdf/2511.12997
permalink: 2025-11-21/2511.12997/
title: Forgetful AI No More&#58; New Framework ‘WebCoach’ Gives Web Agents Long-Term
  Memory
---



In a significant step toward developing truly robust AI, researchers have introduced WebCoach, a model-agnostic framework that equips large language model (LLM) agents with persistent, cross-session memory, allowing them to learn from past successes and failures without continuous retraining.

While multimodal LLMs have shown impressive skills in navigating complex web interfaces—from booking flights to filling out forms—they typically suffer from a critical limitation: they forget repetitive errors and successful workflows once a browsing task ends. This absence of long-term memory limits their efficiency and robustness. WebCoach solves this by layering a memory-aware guidance system onto existing web agents, yielding substantial gains. For instance, testing on the real-world WebVoyager benchmark showed that an agent using the Skywork-38B LLM improved its task success rate from 47% to a remarkable 61%—a 14-point leap—while maintaining or reducing the average number of actions required.

The framework operates through three decoupled components that act as a feedback loop. First, the **WebCondenser** standardizes raw navigation logs (actions, observations, rewards) into concise, semantic summaries. Think of it as writing a detailed report of the browsing session, noting the goal and the eventual outcome (success or failure).

These finalized reports are indexed and stored in the **External Memory Store (EMS)**, a vector database that serves as the agent’s institutional knowledge base. When a new task begins, the third component, the **Coach** (itself a small 8B LLM), retrieves the most relevant past experiences from the EMS based on similarity and recency. This Coach then acts as a real-time mentor, intervening selectively during a task to inject advice.

This intervention is crucial for building intuition. Consider an agent tasked with finding the available colors for a HomePod mini on Apple’s website. If the agent previously failed on a similar task (e.g., finding MacBook Air specifications) by clicking into a repetitive navigational loop, the Coach retrieves this failure episode. Based on this memory, the Coach injects a concise system message mid-task: “Based on past experiences, it’s important to avoid getting stuck in loops... Instead, try using the search function with specific terms like ‘HomePod mini color options’ to locate the information directly.”

The key innovation is the continuous self-evolution enabled by a dynamic memory store. As the agent completes more tasks, whether successfully or unsuccessfully, it continually curates and expands its own EMS. This memory-centric design improves planning and reflection, leading to rapid adaptation over time.

The quantitative results highlight the practical impact of this approach. WebCoach consistently boosted performance across open-source models like Qwen-VL-32B, which saw success rates increase from 49.5% to 57.1%. Notably, smaller base models augmented with WebCoach achieved performance comparable to the same web agent utilizing the much larger, proprietary GPT-4o without memory guidance.

By advocating for a paradigm where guidance is derived from experience, WebCoach offers a robust and scalable architecture that moves LLM agents closer to true self-reflective and continual learning capabilities in complex, real-world web environments.