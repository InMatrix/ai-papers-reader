---
layout: paper
pdf_url: https://arxiv.org/pdf/2511.12884
permalink: 2025-11-21/2511.12884/
title: “Agent READMEs” are Messy, Hard to Read, and Dangerously Silent on Security,
  Study Finds
---



Autonomous coding agents—AI systems designed to take high-level goals and write code with minimal human input—are fundamentally reliant on specialized configuration documents known as agent context files, or "Agent READMEs." A new, large-scale empirical study of these critical files reveals that while developers actively maintain them, these documents are generally complex, difficult to read, and overwhelmingly prioritize basic functionality over critical non-functional requirements like security and performance.

Conducted by researchers across Kasetsart University, Queen's University, and the Nara Institute of Science and Technology, the study analyzed 2,303 context files (such as `CLAUDE.md`, `AGENTS.md`, and `copilot-instructions.md`) across 1,925 open-source repositories to characterize how developers instruct their AI teammates.

### Complex Instructions Lead to 'Context Debt'

The research found that these instruction manifests are not simple configuration snippets but extensive, complex artifacts. Claude Code files, for instance, were found to have a median Flesch Reading Ease (FRE) score of 16.6. This score classifies them as "very difficult" to read, comparable to dense academic papers or legal documents, suggesting a significant cognitive load on developers trying to maintain them.

Structurally, developers adopt a shallow hierarchy, typically using a single H1 heading followed by H2 and H3 subsections. This organizational consistency aids quick parsing, but the sheer length of these files—with GitHub Copilot and Claude Code manifests being substantially longer than those for OpenAI Codex—is driving what the authors term "context debt."

Crucially, these files are not static documentation written once and forgotten. The study confirms they are actively maintained, behaving more like evolving configuration code. Updates typically occur in short, rapid bursts and are driven almost exclusively by incremental additions, with minimal content deletions. This indicates a tight, necessary coupling between the context files and the underlying codebase.

### The Critical Gap: Focusing on "How" Not "How Well"

The content analysis identified 16 distinct categories of instructions, revealing a heavy skew toward action-oriented functional guidance. The most prevalent categories include:

*   **Implementation Details** (69.9%), covering coding style and development guidance.
*   **Architecture** (67.7%), defining high-level system design.
*   **Build and Run** (62.3%), outlining command-line instructions for compilation and execution.
*   **Testing** (75.0%), detailing procedures for automated tests.

However, the study identified a significant and potentially dangerous blind spot concerning non-functional requirements (NFRs). Instructions related to **Security** and **Performance** were specified in only 14.5% of the files studied. **UI/UX** guidelines were even rarer, present in just 8.7%.

This disparity means agents are extensively coached on *how* to execute tasks functionally—for example, being told the exact `npm run dev` command—but are largely left without guardrails on *how to build it well*.

“If security guidelines are absent from the context file,” the authors warn, “agents may produce functional yet vulnerable code (e.g., SQL injection risks).”

The findings highlight an urgent need for improved practices. The researchers recommend that developers adopt a “configuration-as-code” mindset, treating agent context files with the same rigor as CI/CD workflows, and proactively including mandatory sections for NFRs to prevent quality degradation as AI agents become more autonomous.