---
layout: default
title: 2025-05-23
permalink: /2025-05-23/
---

# 2025-05-23

## Generative AI for Assisting Software Developers

### The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning

**Relevance:** This paper demonstrates that entropy minimization can significantly improve LLMs' performance on coding tasks, without labeled data. This is relevant because it provides a method for improving code generation capabilities of generative AI tools for software developers, such as code completion, bug detection and fixing without relying on labeled data.

ðŸ’¡ **[Summary](2505.15134/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.15134)**

### Learning to Reason via Mixture-of-Thought for Logical Reasoning

**Relevance:** This paper introduces Mixture-of-Thought (MoT), a framework enabling LLMs to reason across natural language, code, and symbolic modalities. This is relevant as it shows promise in enhancing code generation and understanding by combining different reasoning formats, which can directly assist software developers in tasks like debugging and code refactoring.

ðŸ’¡ **[Summary](2505.15817/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.15817)**

### Text Generation Beyond Discrete Token Sampling

**Relevance:** The Mixture of Inputs (MoI) method in this paper enhances autoregressive generation by preserving the token distribution's rich information, which can improve text quality and reasoning capabilities in code generation. This is relevant because better reasoning translates to better code generation, bug fixing, and documentation.

ðŸ’¡ **[Summary](2505.14827/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.14827)**

## AI Agents

### Efficient Agent Training for Computer Use

**Relevance:** This paper describes PC Agent-E, a framework for training AI agents to efficiently use computers. It significantly reduces reliance on large-scale human demonstrations while achieving a remarkable improvement in performance, relevant for developing autonomous agents capable of interacting with digital tools and environments.

ðŸ’¡ **[Summary](2505.13909/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.13909)**

### RLVR-World: Training World Models with Reinforcement Learning

**Relevance:** This paper introduces RLVR-World, which uses reinforcement learning to directly optimize world models for task-specific metrics. Since AI agents need world models to reason and plan, this paper is highly relevant to creating agents that can perceive their environment, reason, and plan actions, which are all key components of AI agents.

ðŸ’¡ **[Summary](2505.13934/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.13934)**

### AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use

**Relevance:** This paper introduces AutoMat, an agent-assisted pipeline that transforms scanning transmission electron microscopy images into atomic crystal structures and predicts their physical properties.  The paper orchestrates external tool calls using a text-only LLM to outperform vision-language models. The success of AutoMat, a multi-tool AI agent, in materials science suggests the potential for applying similar agent architectures to solve HCI tasks.

ðŸ’¡ **[Summary](2505.12650/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.12650)**

## Prompt Engineering Techniques

### Prior Prompt Engineering for Reinforcement Fine-Tuning

**Relevance:** This paper investigates the impact of prior prompt engineering (pPE) on reinforcement fine-tuning (RFT) of language models. It explores how different pPE approaches can guide models to internalize distinct behaviors, showing that it's a powerful axis for RFT, which is valuable for instruction fine-tuning.

ðŸ’¡ **[Summary](2505.14157/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.14157)**

### Language Specific Knowledge: Do Models Know Better in X than in English?

**Relevance:** This paper finds that models can perform better when using chain-of-thought reasoning in languages other than English. This is relevant to prompt engineering because understanding and leveraging language-specific knowledge could significantly improve prompt effectiveness, especially in multilingual contexts.

ðŸ’¡ **[Summary](2505.14990/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.14990)**

## Human-in-the-loop Machine Learning

### Web-Shepherd: Advancing PRMs for Reinforcing Web Agents

**Relevance:** This paper proposes the first process reward model (PRM) called Web-Shepherd which could assess web navigation trajectories in a step-level. The study constructs the WebPRM Collection, a large-scale dataset with 40K step-level preference pairs and annotated checklists. By creating a system to evaluate web navigation based on preference pairs, the paper explores human feedback on the agent's actions.

ðŸ’¡ **[Summary](2505.15277/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.15277)**

### BLEUBERI: BLEU is a surprisingly effective reward for instruction following

**Relevance:** The work suggests that BLEU, a basic string-matching metric, can match strong reward models in agreement with human preferences on general instruction-following datasets. The creation of BLEUBERI can inform how we incorporate human feedback for reinforcement learning.

ðŸ’¡ **[Summary](2505.11080/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.11080)**

## Techniques for Explaining AI Behavior

### Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs

**Relevance:** This paper introduces BiasLens, a framework for bias analysis based on the model's vector space, using Concept Activation Vectors and Sparse Autoencoders to extract interpretable concept representations. It's relevant to XAI as it offers a scalable, interpretable, and efficient paradigm for bias discovery, which aids in understanding and explaining AI behavior.

ðŸ’¡ **[Summary](2505.15524/)** ðŸ“„ **[Full paper](https://arxiv.org/pdf/2505.15524)**

