---
layout: paper
pdf_url: https://arxiv.org/pdf/2512.01453
permalink: 2025-12-12/2512.01453/
title: Reinventing Clinical Dialogue&#58; New Taxonomy Maps the Future of Autonomous
  Healthcare AI
---



A pivotal transformation is underway in medical artificial intelligence, moving beyond reactive chatbots and passive text generation toward autonomous, goal-directed systems the authors term "agents." A new survey by researchers at Tianjin University and the Chinese Academy of Sciences provides a first-principles framework for understanding this shift, categorizing these LLM-enabled clinical systems based on their foundational trade-offs: generative creativity versus factual reliability, and operational autonomy versus clinical safety.

Traditional Large Language Models (LLMs) used in medicine are inherently limited by their reactive, stateless nature, which often prioritizes fluent, plausible text over factual veracity—a critical flaw that can lead to "clinically dangerous hallucinations" in high-stakes clinical dialogue.

The **Agentic Paradigm** transcends this by elevating the LLM core into a reasoning engine equipped with cognitive components: **strategic planning** to break down high-level objectives (e.g., diagnosing a rare disease), **persistent memory** to track longitudinal patient history, and **action execution** mechanisms to interact with external tools like Electronic Health Records (EHRs) and clinical guidelines.

To systematically map the diversity of this emerging field, the researchers introduce a novel taxonomy structured along two orthogonal axes:

1.  **Knowledge Source:** Spanning from **Implicit Knowledge Navigation** (relying on the LLM’s vast internal, creative intuition) to **Explicit Knowledge Grounding** (anchoring reasoning in verifiable external databases).
2.  **Agency Objective:** Ranging from **Event Cognition** (understanding and summarizing a clinical situation) to **Goal Execution** (autonomously completing a multi-step workflow).

The intersection of these axes yields four archetypal agent paradigms:

### 1. Latent Space Clinician (LSC)

LSCs rely entirely on the model’s internal, implicit knowledge, simulating a physician’s intuition. They excel at **creative synthesis** and zero-shot reasoning for novel or ambiguous cases.

**Intuition Example:** A sophisticated model like Med-PaLM providing a comprehensive, nuanced answer to a complex, multi-specialty board exam question purely by traversing its pre-trained "medical curriculum." However, they risk hallucination because the answer cannot be externally verified.

### 2. Grounded Synthesizer (GS)

GS agents prioritize reliability by functioning as intelligent interfaces to verifiable external data, such as medical literature or EHRs. They are designed for **factual synthesis** and strict traceability.

**Intuition Example:** A Retrieval-Augmented Generation (RAG) system (like Med-RAG) that translates a patient’s query into a structured API call, retrieves specific, citable paragraphs from clinical guidelines, and synthesizes a response—crucially providing source citations for every assertion.

### 3. Emergent Planner (EP)

Emanating a high degree of autonomy, EPs use their implicit procedural knowledge to dynamically devise and execute novel, multi-step clinical workflows. They are active collaborators, not just consultants.

**Intuition Example:** An agent (like AgentMD) tasked with chronic disease management, which independently generates a dynamic action plan—say, ordering an ECG, interpreting the result, and initiating a prescription—based on its learned procedural understanding, without a rigid pre-set protocol.

### 4. Verifiable Workflow Automator (VWA)

VWA agents maximize safety and predictability. They strictly adhere to predefined, auditable clinical pathways and decision trees, using the LLM as a natural language front-end to execute structured tasks.

**Intuition Example:** A commercial triage bot or a system utilizing an external drug dosage calculator. The LLM translates the user's need into a precise, verifiable tool call, ensuring the high-stakes calculation is performed deterministically and according to protocol, prioritizing correctness over creative planning.

The survey concludes that the path to truly reliable, autonomous AI doctors requires breakthroughs in "neuro-symbolic cognitive architectures" that seamlessly blend the creative power of implicit reasoning with the logical rigor of explicit symbolic systems, while also designing robust safety guardrails for high-stakes execution.