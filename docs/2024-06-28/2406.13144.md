---
layout: paper
pdf_url: https://arxiv.org/pdf/2406.13144
permalink: 2024-06-28/2406.13144/
title: New Dialogue Simulator Reveals Top LLMs Fail Complex, Long-Term Conversations
---



Despite the exponential growth of Large Language Models (LLMs) in building advanced conversational agents, a new study reveals that even the most powerful models struggle profoundly with the complexities of real-world, extended dialogue.

Researchers have introduced **DialSim**, a novel simulation-based evaluation framework, and **LongDialQA**, a challenging new dataset designed specifically to test agents on long-term context retention, multi-party interactions, and multi-hop reasoning—capabilities largely ignored by existing benchmarks.

The core challenge for conversational agents in a real setting is retaining information and making connections over dialogue histories spanning hundreds of thousands of words across multiple sessions. To capture this, LongDialQA was constructed using scripts from long-running, multi-party TV shows like *Friends*, *The Big Bang Theory*, and *The Office*.

This massive dataset comprises over 1,300 dialogue sessions totaling 352,000 tokens. To ensure the agents rely purely on contextual comprehension and not on facts they learned during pre-training, the researchers meticulously anonymized and even swapped main character names.

DialSim simulates a conversation where an LLM is assigned the role of a specific character. As the dialogue progresses across virtual years, other simulated participants spontaneously quiz the agent using questions derived from the LongDialQA dataset.

These questions often require sophisticated recall. For example, a simple recall test might ask, “Who was Patricia dating in 1994?” but DialSim pushes further with multi-hop reasoning across sessions. An agent might be asked: “Linda had a roommate in May 1998. Who was dating this mystery co-habitant by September 22, 1994?” The agent must correctly connect a person mentioned four years apart to answer accurately, or gracefully respond "I don't know" if the context is missing or ambiguous.

The results paint a sobering picture for the current state of conversational AI. State-of-the-art LLMs, including highly capable API models and open-source alternatives, scored consistently below 60% accuracy in the simulation. Even models boasting enormous context windows (up to 1 million tokens), which should theoretically handle the 352K token history, performed poorly.

The findings demonstrate that simply enlarging the context window is insufficient. Models must also possess robust reasoning and memory retrieval capabilities.

Retrieval-Augmented Generation (RAG) methods—which use external memory to search for relevant dialogue history—showed a measurable improvement over models relying on context windows alone. However, even the best RAG configuration still fell short, suggesting current memory management techniques are inadequate for these extended, complex interactions.

Crucially, the performance analysis confirmed that multi-hop questions requiring the agent to connect information spread across two distinct dialogue sessions posed a monumental hurdle, with accuracy dropping significantly compared to simple one-hop fact recall.

The introduction of DialSim and LongDialQA underscores the pressing need for more realistic, challenging benchmarks in conversational AI research, forcing developers to prioritize long-term contextual awareness and rigorous reasoning over superficial fluency.