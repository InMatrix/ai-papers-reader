---
layout: paper
pdf_url: https://arxiv.org/pdf/2406.15718
permalink: 2024-06-28/2406.15718/
title: AI Chatbots Break Free From Turn-Taking With New ‘Duplex Models’
---



A new research paper introduces "duplex models," a foundational shift designed to enable large language models (LLMs) to engage in real-time, human-like conversations that allow for seamless overlaps and interruptions—moving beyond the current clunky, turn-based chat paradigm.

Current LLM interactions operate like a walkie-talkie: one party must finish transmitting the entire message before the other can begin to process and generate a response. This limitation results in conspicuous artificiality and poor responsiveness, frustrating users who expect fluid dialogue.

Researchers from Tsinghua University and affiliated labs address this by proposing a time-division-multiplexing (TDM) encoding-decoding strategy, allowing LLMs to process incoming input and generate output *pseudo-simultaneously*.

### The Duplex Architecture

The core innovation involves converting existing LLMs into duplex models by splitting conversations into small, alternating time slices. Instead of demanding a complete user query before starting, the duplex model processes input incrementally and generates small segments of its response based on these partial inputs.

For instance, dialogue is chunked into small slices, ideally spanning about two seconds, or roughly four to six words—mimicking the natural cognitive pace of human speech. If a user starts speaking while the AI is responding, the duplex model immediately halts its generation, absorbs the new input slice, and dynamically decides whether to respond instantly or signal *idle* and wait for more context. This mechanism emulates the human ability to think, listen, and speak in overlapping contexts.

To train this new conversational style, the researchers developed the first non-turn-based dialogue dataset, **Duplex-UltraChat**. This dataset was created by heuristically injecting various realistic interruptions into conventional dialogue data, ensuring the model learns robustness. These simulated scenarios include:

1.  **Generation Termination:** The user forcibly cuts off the AI mid-sentence (e.g., "Sorry to interrupt, but I have something urgent to add...").
2.  **Regeneration:** The user interrupts because they are dissatisfied with the model's current response and instantly re-prompts the model.
3.  **Back on Topic:** The user interjects with a question before the AI finishes, but the AI must answer the interruption and then coherently resume its unfinished original statement.

### Outperforming Vanilla LLMs

The researchers implemented their strategy on a lightweight model, creating **MiniCPM-duplex**. Benchmarking results show that adapting the model to the duplex configuration did not significantly degrade performance on standard benchmarks (like MMLU or HumanEval), confirming the strategy’s viability.

However, the true difference was revealed in human evaluations. When compared to the vanilla MiniCPM model in interactive, voice-based demos, MiniCPM-duplex showed massive improvements. Participants rated the duplex model 81.05% higher in responsiveness, 43.37% higher in human-likeness, and 32.52% higher in overall satisfaction.

The researchers note that the duplex model’s ability to dynamically infer when to speak and when to remain silent is essential for achieving this enhanced human-likeness, positioning duplex models as an important step toward building AI assistants capable of truly natural conversation. The next challenge, they suggest, is developing better decoding strategies to ensure the chunked text output can be synthesized into a smooth, continuous voice rather than a disjointed series of audio clips.