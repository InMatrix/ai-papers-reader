---
layout: paper
pdf_url: https://arxiv.org/pdf/2601.20789
permalink: 2026-01-30/2601.20789/
title: SERA&#58; New Open-Source Coding Agent Achieves State-of-the-Art Performance
  at a Fraction of the Cost
---



Researchers at the Allen Institute for AI (Ai2) have unveiled SERA (Soft-Verified Efficient Repository Agents), a powerful 32-billion parameter coding agent that dramatically lowers the barriers to training specialized software development AI. By introducing a novel synthetic data pipeline called Soft Verified Generation (SVG), SERA achieves state-of-the-art results among fully open-source models on the demanding SWE-bench Verified benchmark while slashing training costs by up to 57 times compared to prior methods.

The key advantage of open-weight coding agents—the ability to specialize them to private, proprietary codebases—has historically been confined to theory due to the immense cost and complexity of training. Existing approaches rely either on unstable reinforcement learning (RL), which requires large, expensive compute clusters, or complex synthetic data generation that necessitates setting up full sandbox environments and passing unit tests for verification.

SERA bypasses this infrastructure headache using SVG, a dual-rollout system that generates high-quality training data without executing a single unit test.

### The Innovation: Soft Verification

SVG's efficiency stems from two key simplifications. First, it abandons traditional unit test verification for "soft verification." Instead of confirming a patch fixes a bug by passing tests, SERA measures the line-by-line overlap between two patches generated by the teacher model.

The process involves two steps: In Rollout 1, the teacher model (such as GLM-4.6) is given a vague instruction, like "Refactor function X for clarity," and produces a reference patch (Patch A). In Rollout 2, the teacher is given the high-level description of Patch A and asked to reproduce the change, creating Patch B. If Patch B contains a high recall (e.g., 50% overlap) of the lines in Patch A, the data is accepted for training.

This crucial simplification removes the need for complex, bug-focused data pipelines, enabling rapid data generation from virtually any repository, regardless of test coverage.

Second, the system deliberately uses vague instructions (e.g., refactoring or documentation tweaks) rather than focusing solely on bug fixes. The researchers found that this general coding data is equally effective, reflecting real-world tasks more closely than purely bug-focused data.

### Cost and Specialization Breakthroughs

The resulting efficiency is profound. SERA achieves performance equivalent to that of leading models like SkyRL-Agent at 26 times less cost than RL-based training and 57 times less cost than traditional hard-verified synthetic data methods like SWE-smith. The total cost for SERA’s data generation and supervised fine-tuning (SFT) was approximately \$2,000 (40 GPU days). SERA-32B achieves a 49.5% resolve rate on SWE-bench Verified, matching larger open-weight models.

Crucially, SERA enables practical repository specialization. For instance, fine-tuning SERA on the widely used Django codebase allowed the specialized agent to match or exceed the performance of its teacher model (GLM-4.5-Air) on Django-specific tasks using only 8,000 samples, a process costing around \$1,300. This specialization is highly sample efficient—training exclusively on general data required 3.5 times more samples to reach equivalent accuracy.

This specialization capability is particularly significant for small companies or enterprises working with proprietary code. Because SERA is open-source, developers can train a small, local model specialized to their codebase immediately, without exposing sensitive intellectual property to third-party APIs.

Ai2 has released SERA, along with over 200,000 synthetic trajectories and all code, aiming to democratize coding agent research currently concentrated among a few well-resourced industry labs.