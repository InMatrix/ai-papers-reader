## Research Question: How are users involved in the evaluation of AI systems?

- *Relevant Paper*: **Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages**
    - *Why it's relevant*: This paper introduces a novel benchmark specifically designed to evaluate the quality of PDDL code generated by language models from natural language descriptions of planning tasks.  It  goes beyond traditional evaluation methods (that only focus on syntax) by introducing a PDDL equivalence algorithm that rigorously checks the semantic correctness of the generated code.  This evaluation approach inherently incorporates user judgment by requiring that the generated code aligns with the user-provided natural language description.
    - *Read more*: https://arxiv.org/pdf/2407.03321

## Research Question: What are the novel prompt engineering techniques that improve the performance of AI systems?

- *Relevant Paper*: **Magic Insert: Style-Aware Drag-and-Drop**
    - *Why it's relevant*: This paper presents a method for incorporating style into drag-and-drop interactions, enabling users to insert objects from one image into another while preserving the style of the target image. This involves fine-tuning a pre-trained text-to-image diffusion model using LoRA and learned text tokens.  This is an example of prompt engineering that leverages pre-trained models for specific style-based tasks.
    - *Read more*: https://arxiv.org/pdf/2407.02489

- *Relevant Paper*: **SLIMER: Show Less, Instruct More: Enriching Prompts with Definitions and Guidelines for Zero-Shot NER**
    - *Why it's relevant*: This paper proposes a novel approach for zero-shot NER,  which leverages prompts enriched with definitions and guidelines to improve the model's performance on unseen named entity tags. The paper demonstrates that enriching prompts with definitions and guidelines can significantly enhance model performance, making it more robust to unseen entities. 
    - *Read more*: https://arxiv.org/pdf/2407.01272

## Research Question: How can the human-in-the-loop approach improve the model training process?

- *Relevant Paper*: **Auto Cherry-Picker: Learning from High-quality Generative Data Driven by Language**
    - *Why it's relevant*: This paper presents a framework for generating high-quality training data for perception tasks using a human-in-the-loop approach. It leverages language models to generate descriptions and layouts, which are then used to generate images with a new metric to ensure quality. This approach enables users to guide the model training process by providing initial concepts and validating generated data. 
    - *Read more*: https://arxiv.org/pdf/2406.20085

- *Relevant Paper*: **ProgressGym: Alignment with a Millennium of Moral Progress**
    - *Why it's relevant*: This paper introduces ProgressGym, a framework that allows the learning of moral progress mechanics from history, enabling the development of algorithms for progress alignment.  It enables a human-in-the-loop approach by providing a way for users to codify real-world progress alignment challenges into concrete benchmarks, thereby providing a framework for human-guided AI development.
    - *Read more*: https://arxiv.org/pdf/2406.20087

- *Relevant Paper*: **DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging**
    - *Why it's relevant*: This paper proposes a framework for integrating domain-specific knowledge into reward models used in reinforcement learning from human feedback (RLHF). By merging domain-specific models, DogeRM allows for a more efficient and user-friendly approach to customizing reward functions based on specific human preferences. 
    - *Read more*: https://arxiv.org/pdf/2407.01470

## Research Question: What are the latest applications of generative AI in user interface design and engineering?

- *Relevant Paper*: **Magic Insert: Style-Aware Drag-and-Drop**
    - *Why it's relevant*: This paper explores the application of generative AI in user interface design and engineering, specifically focusing on drag-and-drop functionality with style awareness.  This  has implications for creating more personalized and aesthetically pleasing user interfaces, particularly in applications where users require precise control over visual elements.
    - *Read more*: https://arxiv.org/pdf/2407.02489

## Research Question: How to make it easier to explain AI systemâ€™s behavior?

- *Relevant Paper*: **Understanding Alignment in Multimodal LLMs: A Comprehensive Study**
    - *Why it's relevant*: This paper provides a comprehensive analysis of preference alignment in Multimodal LLMs (MLLMs), exploring techniques that encourage these models to align responses more closely with image information. This aligns with the goal of improving the explainability of AI systems by enabling users to understand how the model arrives at its conclusions, especially in the context of multimodal data.
    - *Read more*: https://arxiv.org/pdf/2407.02477

- *Relevant Paper*: **Agentless: Demystifying LLM-based Software Engineering Agents**
    - *Why it's relevant*: This paper presents a simplified approach to automatically solving software development problems without the use of complex agents.  By focusing on a two-phase process of localization followed by repair, Agentless offers a more transparent and interpretable way of explaining the behavior of LLM-based systems in software development.
    - *Read more*: https://arxiv.org/pdf/2407.01489

- *Relevant Paper*: **Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical Reasoning**
    - *Why it's relevant*: This paper proposes a method for automatically providing stepwise error supervision during training, improving the model's ability to understand reasoning errors and produce accurate solutions.  This enhanced error-detection capability allows for more transparent and explainable AI behavior, particularly in mathematical reasoning tasks.
    - *Read more*: https://arxiv.org/pdf/2407.00782

- *Relevant Paper*: **Revealing Fine-Grained Values and Opinions in Large Language Models**
    - *Why it's relevant*: This paper proposes a method for analyzing LLMs' responses to survey questions, identifying patterns in the text that reveal latent values and opinions. By understanding these underlying biases and motivations, users can better understand the AI system's behavior and potentially mitigate negative consequences.
    - *Read more*: https://arxiv.org/pdf/2406.19238

- *Relevant Paper*: **Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs**
    - *Why it's relevant*: This paper investigates the implicit vocabulary of LLMs by examining token representations across layers and identifying "erasure" effects. Understanding these implicit vocabularies can shed light on the internal workings of LLMs, providing valuable insights into their decision-making process and contributing to improved explainability.
    - *Read more*: https://arxiv.org/pdf/2406.20086
